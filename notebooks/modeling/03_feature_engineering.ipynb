{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd114931",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "- Phase 1: Bureau (credit history)\n",
    "- Phase 2: Bureau Balance (monthly credit status)\n",
    "- Phase 3: Previous Applications\n",
    "- Phase 4: POS & Credit Card\n",
    "- Phase 5: Installments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "c1fff7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "import json\n",
    "import os\n",
    "\n",
    "from credit_model_helpers import (\n",
    "    aggregate_numeric, aggregate_categorical_ohe,\n",
    "    filter_by_missing, remove_low_variance, remove_correlated,\n",
    "    get_feature_importances, select_by_importance_threshold,\n",
    "    train_preliminary_model, compare_feature_sets, print_comparison_results\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "mlflow.lightgbm.autolog(disable=True)\n",
    "mlflow.xgboost.autolog(disable=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0e976f",
   "metadata": {},
   "source": [
    "### Setup: Feature Definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "21e6cbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline features: 36 (25 num + 11 cat)\n"
     ]
    }
   ],
   "source": [
    "NUMERICAL_FEATURES = [\n",
    "    'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE',\n",
    "    'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH',\n",
    "    'DAYS_LAST_PHONE_CHANGE', 'REGION_POPULATION_RELATIVE',\n",
    "    'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE',\n",
    "    'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3',\n",
    "    'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY',\n",
    "    'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON',\n",
    "    'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR',\n",
    "    'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE',\n",
    "    'CNT_FAM_MEMBERS', 'HOUR_APPR_PROCESS_START'\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES = [\n",
    "    'NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY',\n",
    "    'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS',\n",
    "    'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE', 'WEEKDAY_APPR_PROCESS_START',\n",
    "    'ORGANIZATION_TYPE'\n",
    "]\n",
    "\n",
    "BASELINE_FEATURES = NUMERICAL_FEATURES + CATEGORICAL_FEATURES\n",
    "\n",
    "def create_cat_mappings(X_train, cat_cols):\n",
    "    mappings = {}\n",
    "    for col in cat_cols:\n",
    "        unique_vals = X_train[col].dropna().unique()\n",
    "        mappings[col] = {val: i for i, val in enumerate(unique_vals)}\n",
    "    return mappings\n",
    "\n",
    "print(f\"Baseline features: {len(BASELINE_FEATURES)} ({len(NUMERICAL_FEATURES)} num + {len(CATEGORICAL_FEATURES)} cat)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "50d90a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 246008, Val: 61503, Test: 48744\n",
      "Categorical mappings created for 11 features\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/raw/application_train.csv')\n",
    "test_df = pd.read_csv('../../data/raw/application_test.csv')\n",
    "\n",
    "X = df[BASELINE_FEATURES].copy()\n",
    "y = df['TARGET'].copy()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "cat_mappings = create_cat_mappings(X_train, CATEGORICAL_FEATURES)\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(test_df)}\")\n",
    "print(f\"Categorical mappings created for {len(cat_mappings)} features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2e035",
   "metadata": {},
   "source": [
    "### Phase 1: Bureau Features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d471b5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bureau shape: (1716428, 17)\n",
      "Unique SK_ID_CURR: 305811\n"
     ]
    }
   ],
   "source": [
    "bureau = pd.read_csv('../../data/raw/bureau.csv')\n",
    "print(f\"Bureau shape: {bureau.shape}\")\n",
    "print(f\"Unique SK_ID_CURR: {bureau['SK_ID_CURR'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e6a9f1",
   "metadata": {},
   "source": [
    "### Bureau Aggregations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8b832433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bureau aggregated features: 27\n"
     ]
    }
   ],
   "source": [
    "bureau_agg = bureau.groupby('SK_ID_CURR').agg({\n",
    "    'DAYS_CREDIT': ['min', 'max', 'mean', 'std'],\n",
    "    'CREDIT_DAY_OVERDUE': ['max', 'mean', 'sum'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM': ['sum', 'mean', 'std', 'max'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['sum', 'mean', 'max'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['sum', 'max'],\n",
    "    'AMT_CREDIT_SUM_LIMIT': ['sum', 'mean', 'max'],\n",
    "    'DAYS_CREDIT_UPDATE': ['min', 'max', 'mean']\n",
    "}).reset_index()\n",
    "\n",
    "bureau_agg.columns = ['SK_ID_CURR'] + [f'bureau_{col[0]}_{col[1]}' for col in bureau_agg.columns[1:]]\n",
    "\n",
    "print(f\"Bureau aggregated features: {bureau_agg.shape[1] - 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3d369aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bureau aggregated features: 27\n"
     ]
    }
   ],
   "source": [
    "bureau_agg = bureau.groupby('SK_ID_CURR').agg({\n",
    "    'DAYS_CREDIT': ['min', 'max', 'mean', 'std'],\n",
    "    'CREDIT_DAY_OVERDUE': ['max', 'mean', 'sum'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM': ['sum', 'mean', 'std', 'max'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['sum', 'mean', 'max'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['sum', 'max'],\n",
    "    'AMT_CREDIT_SUM_LIMIT': ['sum', 'mean', 'max'],\n",
    "    'DAYS_CREDIT_UPDATE': ['min', 'max', 'mean']\n",
    "}).reset_index()\n",
    "\n",
    "bureau_agg.columns = ['SK_ID_CURR'] + [f'bureau_{col[0]}_{col[1]}' for col in bureau_agg.columns[1:]]\n",
    "\n",
    "print(f\"Bureau aggregated features: {bureau_agg.shape[1] - 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2283d325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total bureau features after categorical: 46\n"
     ]
    }
   ],
   "source": [
    "bureau_active = aggregate_categorical_ohe(bureau, 'SK_ID_CURR', 'CREDIT_ACTIVE', 'bureau_active')\n",
    "bureau_type = aggregate_categorical_ohe(bureau, 'SK_ID_CURR', 'CREDIT_TYPE', 'bureau_type')\n",
    "\n",
    "bureau_agg = bureau_agg.merge(bureau_active, on='SK_ID_CURR', how='left')\n",
    "bureau_agg = bureau_agg.merge(bureau_type, on='SK_ID_CURR', how='left')\n",
    "\n",
    "print(f\"Total bureau features after categorical: {bureau_agg.shape[1] - 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2244f454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features with derived: 52\n"
     ]
    }
   ],
   "source": [
    "bureau_agg['bureau_debt_credit_ratio'] = bureau_agg['bureau_AMT_CREDIT_SUM_DEBT_sum'] / (bureau_agg['bureau_AMT_CREDIT_SUM_sum'] + 1)\n",
    "bureau_agg['bureau_overdue_debt_ratio'] = bureau_agg['bureau_AMT_CREDIT_SUM_OVERDUE_sum'] / (bureau_agg['bureau_AMT_CREDIT_SUM_DEBT_sum'] + 1)\n",
    "bureau_agg['bureau_active_closed_ratio'] = bureau_agg['bureau_active_Active'] / (bureau_agg['bureau_active_Closed'] + 1)\n",
    "\n",
    "if 'bureau_active_Bad debt' in bureau_agg.columns:\n",
    "    bureau_agg['bureau_bad_debt_ratio'] = bureau_agg['bureau_active_Bad debt'] / (bureau_agg[['bureau_active_Active', 'bureau_active_Closed']].sum(axis=1) + 1)\n",
    "\n",
    "bureau_agg['bureau_credit_count'] = bureau.groupby('SK_ID_CURR').size().values\n",
    "bureau_agg['bureau_avg_days_between'] = bureau_agg['bureau_DAYS_CREDIT_max'] - bureau_agg['bureau_DAYS_CREDIT_min']\n",
    "\n",
    "print(f\"Total features with derived: {bureau_agg.shape[1] - 1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae239a",
   "metadata": {},
   "source": [
    "### Level 1 Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a36bd85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering: 52 features\n",
      "Dropped 0 features (>80% missing)\n",
      "Dropped 11 features (low variance)\n",
      "Dropped 5 features (high correlation)\n",
      "\\nAfter Level 1 filtering: 36 features\n"
     ]
    }
   ],
   "source": [
    "bureau_features = bureau_agg.drop(columns=['SK_ID_CURR']).select_dtypes(include=[np.number])\n",
    "\n",
    "print(f\"Before filtering: {bureau_features.shape[1]} features\")\n",
    "\n",
    "bureau_features, dropped_missing = filter_by_missing(bureau_features, threshold=0.80)\n",
    "print(f\"Dropped {len(dropped_missing)} features (>80% missing)\")\n",
    "\n",
    "bureau_features, dropped_variance = remove_low_variance(bureau_features, threshold=0.01)\n",
    "print(f\"Dropped {len(dropped_variance)} features (low variance)\")\n",
    "\n",
    "bureau_features, dropped_corr = remove_correlated(bureau_features, threshold=0.95)\n",
    "print(f\"Dropped {len(dropped_corr)} features (high correlation)\")\n",
    "\n",
    "print(f\"\\\\nAfter Level 1 filtering: {bureau_features.shape[1]} features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a44aec8",
   "metadata": {},
   "source": [
    "### Merge with Train/Val/Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b6154217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (246008, 72)\n",
      "Val shape: (61503, 72)\n",
      "Test shape: (48744, 72)\n"
     ]
    }
   ],
   "source": [
    "bureau_agg_filtered = pd.concat([bureau_agg[['SK_ID_CURR']], bureau_features], axis=1)\n",
    "\n",
    "train_ids = df.loc[X_train.index, 'SK_ID_CURR']\n",
    "val_ids = df.loc[X_val.index, 'SK_ID_CURR']\n",
    "\n",
    "X_train_bureau = pd.merge(\n",
    "    pd.concat([train_ids.reset_index(drop=True), X_train.reset_index(drop=True)], axis=1),\n",
    "    bureau_agg_filtered, on='SK_ID_CURR', how='left'\n",
    ").drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "X_val_bureau = pd.merge(\n",
    "    pd.concat([val_ids.reset_index(drop=True), X_val.reset_index(drop=True)], axis=1),\n",
    "    bureau_agg_filtered, on='SK_ID_CURR', how='left'\n",
    ").drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "X_test_bureau = pd.merge(\n",
    "    test_df[['SK_ID_CURR'] + BASELINE_FEATURES],\n",
    "    bureau_agg_filtered, on='SK_ID_CURR', how='left'\n",
    ").drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "print(f\"Train shape: {X_train_bureau.shape}\")\n",
    "print(f\"Val shape: {X_val_bureau.shape}\")\n",
    "print(f\"Test shape: {X_test_bureau.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f038f3a7",
   "metadata": {},
   "source": [
    "### Preliminary Training (for Level 2 Filtering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b1ce222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM training complete\n",
      "CPU times: total: 23.3 s\n",
      "Wall time: 4.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train_lgb = X_train_bureau.copy()\n",
    "X_val_lgb = X_val_bureau.copy()\n",
    "X_test_lgb = X_test_bureau.copy()\n",
    "\n",
    "for col in CATEGORICAL_FEATURES:\n",
    "    if col in X_train_lgb.columns:\n",
    "        X_train_lgb[col] = X_train_lgb[col].map(cat_mappings[col])\n",
    "        X_val_lgb[col] = X_val_lgb[col].map(cat_mappings[col])\n",
    "        X_test_lgb[col] = X_test_lgb[col].map(cat_mappings[col])\n",
    "\n",
    "lgb_bureau = LGBMClassifier(\n",
    "    #n_estimators=500,\n",
    "    #learning_rate=0.05,\n",
    "    #max_depth=7,\n",
    "    #num_leaves=31,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_bureau.fit(\n",
    "    X_train_lgb, y_train,\n",
    "    eval_set=[(X_val_lgb, y_val)],\n",
    "    eval_metric='auc'\n",
    ")\n",
    "\n",
    "print(\"LightGBM training complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "be460d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preliminary LightGBM Results:\n",
      "  Train AUC: 0.8043\n",
      "  Val AUC: 0.7645\n"
     ]
    }
   ],
   "source": [
    "train_auc_lgb_prelim = roc_auc_score(y_train, lgb_bureau.predict_proba(X_train_lgb)[:, 1])\n",
    "val_auc_lgb_prelim = roc_auc_score(y_val, lgb_bureau.predict_proba(X_val_lgb)[:, 1])\n",
    "\n",
    "print(\"Preliminary LightGBM Results:\")\n",
    "print(f\"  Train AUC: {train_auc_lgb_prelim:.4f}\")\n",
    "print(f\"  Val AUC: {val_auc_lgb_prelim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a885f159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preliminary XGBoost Results:\n",
      "  Train AUC: 0.9077\n",
      "  Val AUC: 0.7594\n",
      "CPU times: total: 5min 3s\n",
      "Wall time: 23.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb_bureau = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    scale_pos_weight=11.4,\n",
    "    random_state=42,\n",
    "    tree_method='hist',\n",
    "    eval_metric='auc',\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb_bureau.fit(\n",
    "    X_train_lgb, y_train,\n",
    "    eval_set=[(X_val_lgb, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "train_auc_xgb_prelim = roc_auc_score(y_train, xgb_bureau.predict_proba(X_train_lgb)[:, 1])\n",
    "val_auc_xgb_prelim = roc_auc_score(y_val, xgb_bureau.predict_proba(X_val_lgb)[:, 1])\n",
    "\n",
    "print(\"\\nPreliminary XGBoost Results:\")\n",
    "print(f\"  Train AUC: {train_auc_xgb_prelim:.4f}\")\n",
    "print(f\"  Val AUC: {val_auc_xgb_prelim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e7b640",
   "metadata": {},
   "source": [
    "### Level 2 Filtering: Feature Importance Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "48ea5025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 LightGBM Importances:\n",
      "                           feature  importance\n",
      "12                    EXT_SOURCE_1         245\n",
      "14                    EXT_SOURCE_3         183\n",
      "13                    EXT_SOURCE_2         180\n",
      "4                       DAYS_BIRTH         162\n",
      "1                       AMT_CREDIT         142\n",
      "2                      AMT_ANNUITY         112\n",
      "3                  AMT_GOODS_PRICE         101\n",
      "5                    DAYS_EMPLOYED          86\n",
      "43  bureau_DAYS_CREDIT_ENDDATE_max          85\n",
      "7                  DAYS_ID_PUBLISH          81\n",
      "\n",
      "Top 10 XGBoost Importances:\n",
      "                     feature  importance\n",
      "14              EXT_SOURCE_3    0.059793\n",
      "13              EXT_SOURCE_2    0.049448\n",
      "26               CODE_GENDER    0.039989\n",
      "25        NAME_CONTRACT_TYPE    0.031664\n",
      "30       NAME_EDUCATION_TYPE    0.031238\n",
      "27              FLAG_OWN_CAR    0.023732\n",
      "65     bureau_type_Microloan    0.023571\n",
      "12              EXT_SOURCE_1    0.023311\n",
      "66      bureau_type_Mortgage    0.020177\n",
      "67  bureau_debt_credit_ratio    0.018462\n",
      "\n",
      "Threshold: 20\n",
      "LightGBM selected: 48\n",
      "XGBoost selected: 0\n",
      "Common features: 0\n",
      "Union features: 48\n",
      "\n",
      "Using UNION: 48 features selected\n"
     ]
    }
   ],
   "source": [
    "lgb_importances = get_feature_importances(lgb_bureau, X_train_lgb.columns.tolist())\n",
    "xgb_importances = get_feature_importances(xgb_bureau, X_train_lgb.columns.tolist())\n",
    "\n",
    "print(\"\\nTop 10 LightGBM Importances:\")\n",
    "print(lgb_importances.head(10))\n",
    "\n",
    "print(\"\\nTop 10 XGBoost Importances:\")\n",
    "print(xgb_importances.head(10))\n",
    "\n",
    "importance_threshold = 20\n",
    "lgb_selected_features = select_by_importance_threshold(lgb_importances, importance_threshold)\n",
    "xgb_selected_features = select_by_importance_threshold(xgb_importances, importance_threshold)\n",
    "\n",
    "common_features = list(set(lgb_selected_features) & set(xgb_selected_features))\n",
    "all_selected = list(set(lgb_selected_features) | set(xgb_selected_features))\n",
    "\n",
    "print(f\"\\nThreshold: {importance_threshold}\")\n",
    "print(f\"LightGBM selected: {len(lgb_selected_features)}\")\n",
    "print(f\"XGBoost selected: {len(xgb_selected_features)}\")\n",
    "print(f\"Common features: {len(common_features)}\")\n",
    "print(f\"Union features: {len(all_selected)}\")\n",
    "\n",
    "selected_features = all_selected\n",
    "print(f\"\\nUsing UNION: {len(selected_features)} features selected\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7270cc7b",
   "metadata": {},
   "source": [
    "### Final Model Training (with selected features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f5ae4f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features shape:\n",
      "  Train: (246008, 48)\n",
      "  Val: (61503, 48)\n",
      "  Test: (48744, 48)\n"
     ]
    }
   ],
   "source": [
    "X_train_selected = X_train_lgb[selected_features]\n",
    "X_val_selected = X_val_lgb[selected_features]\n",
    "X_test_selected = X_test_lgb[selected_features]\n",
    "\n",
    "print(f\"Selected features shape:\")\n",
    "print(f\"  Train: {X_train_selected.shape}\")\n",
    "print(f\"  Val: {X_val_selected.shape}\")\n",
    "print(f\"  Test: {X_test_selected.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "f06fe6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final LightGBM Results:\n",
      "  Train AUC: 0.8444\n",
      "  Val AUC: 0.7665\n",
      "CPU times: total: 1min 11s\n",
      "Wall time: 9.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgb_final = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_final.fit(\n",
    "    X_train_selected, y_train,\n",
    "    eval_set=[(X_val_selected, y_val)],\n",
    "    eval_metric='auc'\n",
    ")\n",
    "\n",
    "train_auc_lgb = roc_auc_score(y_train, lgb_final.predict_proba(X_train_selected)[:, 1])\n",
    "val_auc_lgb = roc_auc_score(y_val, lgb_final.predict_proba(X_val_selected)[:, 1])\n",
    "\n",
    "print(\"Final LightGBM Results:\")\n",
    "print(f\"  Train AUC: {train_auc_lgb:.4f}\")\n",
    "print(f\"  Val AUC: {val_auc_lgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "cc840f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final XGBoost Results:\n",
      "  Train AUC: 0.9100\n",
      "  Val AUC: 0.7582\n",
      "CPU times: total: 4min 9s\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb_final = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    scale_pos_weight=11.4,\n",
    "    random_state=42,\n",
    "    tree_method='hist',\n",
    "    eval_metric='auc',\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb_final.fit(\n",
    "    X_train_selected, y_train,\n",
    "    eval_set=[(X_val_selected, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "train_auc_xgb = roc_auc_score(y_train, xgb_final.predict_proba(X_train_selected)[:, 1])\n",
    "val_auc_xgb = roc_auc_score(y_val, xgb_final.predict_proba(X_val_selected)[:, 1])\n",
    "\n",
    "print(\"\\nFinal XGBoost Results:\")\n",
    "print(f\"  Train AUC: {train_auc_xgb:.4f}\")\n",
    "print(f\"  Val AUC: {val_auc_xgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "dd73e5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "QUICK EVALUATION (80/20 Split - Baseline Comparison)\n",
      "============================================================\n",
      "Model                Train AUC    Val AUC      Improvement  Gap     \n",
      "------------------------------------------------------------\n",
      "Baseline             0.8288       0.7610       -            0.0678  \n",
      "LightGBM             0.8444       0.7665       0.0055++++++ 0.0779  \n",
      "XGBoost              0.9100       0.7582       -0.0028+++++ 0.1517  \n",
      "============================================================\n",
      "\n",
      "Selected Features:\n",
      "  Total: 48\n",
      "  Baseline: 24\n",
      "  Bureau: 24\n"
     ]
    }
   ],
   "source": [
    "baseline_train_auc = 0.8288\n",
    "baseline_val_auc = 0.7610\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"QUICK EVALUATION (80/20 Split - Baseline Comparison)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Model':<20} {'Train AUC':<12} {'Val AUC':<12} {'Improvement':<12} {'Gap':<8}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Baseline':<20} {baseline_train_auc:<12.4f} {baseline_val_auc:<12.4f} {'-':<12} {baseline_train_auc - baseline_val_auc:<8.4f}\")\n",
    "print(f\"{'LightGBM':<20} {train_auc_lgb:<12.4f} {val_auc_lgb:<12.4f} {val_auc_lgb - baseline_val_auc:+<12.4f} {train_auc_lgb - val_auc_lgb:<8.4f}\")\n",
    "print(f\"{'XGBoost':<20} {train_auc_xgb:<12.4f} {val_auc_xgb:<12.4f} {val_auc_xgb - baseline_val_auc:+<12.4f} {train_auc_xgb - val_auc_xgb:<8.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "bureau_new_features = [f for f in selected_features if f.startswith('bureau_')]\n",
    "print(f\"\\nSelected Features:\")\n",
    "print(f\"  Total: {len(selected_features)}\")\n",
    "print(f\"  Baseline: {len([f for f in selected_features if not f.startswith('bureau_')])}\")\n",
    "print(f\"  Bureau: {len(bureau_new_features)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce55582",
   "metadata": {},
   "source": [
    "### Cross-Validation (5-Fold StratifiedKFold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b340cf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 5-Fold Cross-Validation...\n",
      "------------------------------------------------------------\n",
      "Fold 1: LightGBM=0.7583, XGBoost=0.7490\n",
      "Fold 2: LightGBM=0.7515, XGBoost=0.7428\n",
      "Fold 3: LightGBM=0.7524, XGBoost=0.7433\n",
      "Fold 4: LightGBM=0.7531, XGBoost=0.7444\n",
      "Fold 5: LightGBM=0.7559, XGBoost=0.7471\n",
      "------------------------------------------------------------\n",
      "\n",
      "LightGBM CV: 0.7543 ± 0.0025\n",
      "XGBoost CV:  0.7453 ± 0.0024\n",
      "\n",
      "Baseline Val AUC: 0.7610\n",
      "LightGBM Improvement: -0.0067\n",
      "XGBoost Improvement:  -0.0157\n",
      "CPU times: total: 24min 24s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_full = pd.concat([X_train, X_val], axis=0).reset_index(drop=True)\n",
    "y_full = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    "\n",
    "X_full_merged = pd.merge(\n",
    "    pd.concat([df.loc[X_full.index, 'SK_ID_CURR'].reset_index(drop=True), X_full], axis=1),\n",
    "    bureau_agg_filtered, on='SK_ID_CURR', how='left'\n",
    ").drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "X_full_selected = X_full_merged[selected_features].copy()\n",
    "for col in CATEGORICAL_FEATURES:\n",
    "    if col in X_full_selected.columns:\n",
    "        X_full_selected[col] = X_full_selected[col].map(cat_mappings[col])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "lgb_cv_scores = []\n",
    "xgb_cv_scores = []\n",
    "\n",
    "print(\"Running 5-Fold Cross-Validation...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_full_selected, y_full), 1):\n",
    "    X_cv_train, X_cv_val = X_full_selected.iloc[train_idx], X_full_selected.iloc[val_idx]\n",
    "    y_cv_train, y_cv_val = y_full.iloc[train_idx], y_full.iloc[val_idx]\n",
    "    \n",
    "    lgb_cv = LGBMClassifier(\n",
    "        n_estimators=500, learning_rate=0.05, max_depth=7,\n",
    "        num_leaves=31, random_state=42, class_weight='balanced', verbose=-1\n",
    "    )\n",
    "    lgb_cv.fit(X_cv_train, y_cv_train, eval_set=[(X_cv_val, y_cv_val)], eval_metric='auc')\n",
    "    lgb_val_auc = roc_auc_score(y_cv_val, lgb_cv.predict_proba(X_cv_val)[:, 1])\n",
    "    lgb_cv_scores.append(lgb_val_auc)\n",
    "    \n",
    "    xgb_cv = XGBClassifier(\n",
    "        n_estimators=500, learning_rate=0.05, max_depth=7,\n",
    "        scale_pos_weight=11.4, random_state=42, tree_method='hist',\n",
    "        eval_metric='auc', verbosity=0\n",
    "    )\n",
    "    xgb_cv.fit(X_cv_train, y_cv_train, eval_set=[(X_cv_val, y_cv_val)], verbose=False)\n",
    "    xgb_val_auc = roc_auc_score(y_cv_val, xgb_cv.predict_proba(X_cv_val)[:, 1])\n",
    "    xgb_cv_scores.append(xgb_val_auc)\n",
    "    \n",
    "    print(f\"Fold {fold}: LightGBM={lgb_val_auc:.4f}, XGBoost={xgb_val_auc:.4f}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"\\nLightGBM CV: {np.mean(lgb_cv_scores):.4f} ± {np.std(lgb_cv_scores):.4f}\")\n",
    "print(f\"XGBoost CV:  {np.mean(xgb_cv_scores):.4f} ± {np.std(xgb_cv_scores):.4f}\")\n",
    "print(f\"\\nBaseline Val AUC: {baseline_val_auc:.4f}\")\n",
    "print(f\"LightGBM Improvement: {np.mean(lgb_cv_scores) - baseline_val_auc:+.4f}\")\n",
    "print(f\"XGBoost Improvement:  {np.mean(xgb_cv_scores) - baseline_val_auc:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1788024c",
   "metadata": {},
   "source": [
    "### Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e79e6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to ../../data/processed/phase1_bureau/\n",
      "  - train_features.csv: (246008, 48)\n",
      "  - val_features.csv: (61503, 48)\n",
      "  - test_features.csv: (48744, 48)\n",
      "  - feature_metadata.json: 48 features\n"
     ]
    }
   ],
   "source": [
    "output_dir = '../../data/processed/phase1_bureau'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "train_ids = df.loc[X_train.index, 'SK_ID_CURR'].reset_index(drop=True)\n",
    "val_ids = df.loc[X_val.index, 'SK_ID_CURR'].reset_index(drop=True)\n",
    "test_ids = test_df['SK_ID_CURR'].reset_index(drop=True)\n",
    "\n",
    "pd.concat([train_ids, X_train_selected.reset_index(drop=True)], axis=1).to_csv(\n",
    "    f'{output_dir}/X_train.csv', index=False\n",
    ")\n",
    "pd.DataFrame(y_train).to_csv(f'{output_dir}/y_train.csv', index=False)\n",
    "\n",
    "pd.concat([val_ids, X_val_selected.reset_index(drop=True)], axis=1).to_csv(\n",
    "    f'{output_dir}/X_val.csv', index=False\n",
    ")\n",
    "pd.DataFrame(y_val).to_csv(f'{output_dir}/y_val.csv', index=False)\n",
    "\n",
    "pd.concat([test_ids, X_test_selected.reset_index(drop=True)], axis=1).to_csv(\n",
    "    f'{output_dir}/X_test.csv', index=False\n",
    ")\n",
    "\n",
    "feature_metadata = {\n",
    "    'phase': 'phase1_bureau',\n",
    "    'n_features_created': 52,\n",
    "    'n_features_after_level1': 36,\n",
    "    'n_features_final': len(selected_features),\n",
    "    'feature_list': selected_features,\n",
    "    'baseline_features': [f for f in selected_features if not f.startswith('bureau_')],\n",
    "    'bureau_features': bureau_new_features,\n",
    "    'dropped_missing': dropped_missing,\n",
    "    'dropped_variance': dropped_variance,\n",
    "    'dropped_corr': dropped_corr,\n",
    "    'importance_threshold': importance_threshold,\n",
    "    'quick_eval': {\n",
    "        'lgb_val_auc': float(val_auc_lgb),\n",
    "        'xgb_val_auc': float(val_auc_xgb)\n",
    "    },\n",
    "    'cv_eval': {\n",
    "        'lgb_cv_mean': float(np.mean(lgb_cv_scores)),\n",
    "        'lgb_cv_std': float(np.std(lgb_cv_scores)),\n",
    "        'xgb_cv_mean': float(np.mean(xgb_cv_scores)),\n",
    "        'xgb_cv_std': float(np.std(xgb_cv_scores))\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f'{output_dir}/feature_metadata.json', 'w') as f:\n",
    "    json.dump(feature_metadata, f, indent=2)\n",
    "\n",
    "print(f\"Saved processed data to {output_dir}/\")\n",
    "print(f\"  - train_features.csv: {X_train_selected.shape}\")\n",
    "print(f\"  - val_features.csv: {X_val_selected.shape}\")\n",
    "print(f\"  - test_features.csv: {X_test_selected.shape}\")\n",
    "print(f\"  - feature_metadata.json: {len(selected_features)} features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46defed",
   "metadata": {},
   "source": [
    "### MLflow Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "34e06948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 22:27:39 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/12 22:27:44 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26468522d00e42c29ee3779a939a6362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged LightGBM to MLflow\n"
     ]
    }
   ],
   "source": [
    "mlflow_tracking_uri = os.path.join(os.getcwd(), 'mlruns')\n",
    "mlflow.set_tracking_uri(f\"file:///{mlflow_tracking_uri}\")\n",
    "mlflow.set_experiment(\"feature_engineering\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"phase1_bureau_lightgbm\"):\n",
    "    mlflow.log_param(\"phase\", \"bureau\")\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM\")\n",
    "    mlflow.log_param(\"n_estimators\", 500)\n",
    "    mlflow.log_param(\"learning_rate\", 0.05)\n",
    "    mlflow.log_param(\"max_depth\", 7)\n",
    "    mlflow.log_param(\"n_baseline_features\", len(BASELINE_FEATURES))\n",
    "    mlflow.log_param(\"n_bureau_features\", len(bureau_new_features))\n",
    "    mlflow.log_param(\"n_features_created\", 52)\n",
    "    mlflow.log_param(\"n_features_after_level1\", 36)\n",
    "    mlflow.log_param(\"n_features_final\", len(selected_features))\n",
    "    mlflow.log_param(\"n_dropped_missing\", len(dropped_missing))\n",
    "    mlflow.log_param(\"n_dropped_variance\", len(dropped_variance))\n",
    "    mlflow.log_param(\"n_dropped_correlation\", len(dropped_corr))\n",
    "    mlflow.log_param(\"importance_threshold\", importance_threshold)\n",
    "    \n",
    "    mlflow.log_metric(\"quick_train_auc\", train_auc_lgb)\n",
    "    mlflow.log_metric(\"quick_val_auc\", val_auc_lgb)\n",
    "    mlflow.log_metric(\"cv_mean_auc\", np.mean(lgb_cv_scores))\n",
    "    mlflow.log_metric(\"cv_std_auc\", np.std(lgb_cv_scores))\n",
    "    mlflow.log_metric(\"baseline_val_auc\", baseline_val_auc)\n",
    "    mlflow.log_metric(\"improvement_quick\", val_auc_lgb - baseline_val_auc)\n",
    "    mlflow.log_metric(\"improvement_cv\", np.mean(lgb_cv_scores) - baseline_val_auc)\n",
    "    mlflow.log_metric(\"train_val_gap\", train_auc_lgb - val_auc_lgb)\n",
    "    \n",
    "    X_sample = X_train_selected.iloc[:5].fillna(0)\n",
    "    y_sample = y_train.iloc[:5]\n",
    "    signature = mlflow.models.infer_signature(X_sample, y_sample)\n",
    "    \n",
    "    mlflow.sklearn.log_model(lgb_final, \"model\", signature=signature, input_example=X_sample)\n",
    "    \n",
    "    lgb_final_importances = get_feature_importances(lgb_final, selected_features)\n",
    "    lgb_final_importances.to_csv('feature_importance_lgb.csv', index=False)\n",
    "    mlflow.log_artifact('feature_importance_lgb.csv')\n",
    "    os.remove('feature_importance_lgb.csv')\n",
    "    \n",
    "    with open('selected_features.json', 'w') as f:\n",
    "        json.dump({'features': selected_features}, f, indent=2)\n",
    "    mlflow.log_artifact('selected_features.json')\n",
    "    os.remove('selected_features.json')\n",
    "    \n",
    "    with open('dropped_features.json', 'w') as f:\n",
    "        json.dump({\n",
    "            'dropped_missing': dropped_missing,\n",
    "            'dropped_variance': dropped_variance,\n",
    "            'dropped_correlation': dropped_corr\n",
    "        }, f, indent=2)\n",
    "    mlflow.log_artifact('dropped_features.json')\n",
    "    os.remove('dropped_features.json')\n",
    "\n",
    "print(\"Logged LightGBM to MLflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "762fb381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 22:27:45 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/12 22:27:49 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba69b71cc5e3433a9890c7bcb920b803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged XGBoost to MLflow\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"phase1_bureau_xgboost\"):\n",
    "    mlflow.log_param(\"phase\", \"bureau\")\n",
    "    mlflow.log_param(\"model_type\", \"XGBoost\")\n",
    "    mlflow.log_param(\"n_estimators\", 500)\n",
    "    mlflow.log_param(\"learning_rate\", 0.05)\n",
    "    mlflow.log_param(\"max_depth\", 7)\n",
    "    mlflow.log_param(\"n_baseline_features\", len(BASELINE_FEATURES))\n",
    "    mlflow.log_param(\"n_bureau_features\", len(bureau_new_features))\n",
    "    mlflow.log_param(\"n_features_created\", 52)\n",
    "    mlflow.log_param(\"n_features_after_level1\", 36)\n",
    "    mlflow.log_param(\"n_features_final\", len(selected_features))\n",
    "    mlflow.log_param(\"n_dropped_missing\", len(dropped_missing))\n",
    "    mlflow.log_param(\"n_dropped_variance\", len(dropped_variance))\n",
    "    mlflow.log_param(\"n_dropped_correlation\", len(dropped_corr))\n",
    "    mlflow.log_param(\"importance_threshold\", importance_threshold)\n",
    "    \n",
    "    mlflow.log_metric(\"quick_train_auc\", train_auc_xgb)\n",
    "    mlflow.log_metric(\"quick_val_auc\", val_auc_xgb)\n",
    "    mlflow.log_metric(\"cv_mean_auc\", np.mean(xgb_cv_scores))\n",
    "    mlflow.log_metric(\"cv_std_auc\", np.std(xgb_cv_scores))\n",
    "    mlflow.log_metric(\"baseline_val_auc\", baseline_val_auc)\n",
    "    mlflow.log_metric(\"improvement_quick\", val_auc_xgb - baseline_val_auc)\n",
    "    mlflow.log_metric(\"improvement_cv\", np.mean(xgb_cv_scores) - baseline_val_auc)\n",
    "    mlflow.log_metric(\"train_val_gap\", train_auc_xgb - val_auc_xgb)\n",
    "    \n",
    "    mlflow.sklearn.log_model(xgb_final, \"model\", signature=signature, input_example=X_sample)\n",
    "    \n",
    "    xgb_final_importances = get_feature_importances(xgb_final, selected_features)\n",
    "    xgb_final_importances.to_csv('feature_importance_xgb.csv', index=False)\n",
    "    mlflow.log_artifact('feature_importance_xgb.csv')\n",
    "    os.remove('feature_importance_xgb.csv')\n",
    "    \n",
    "    with open('selected_features.json', 'w') as f:\n",
    "        json.dump({'features': selected_features}, f, indent=2)\n",
    "    mlflow.log_artifact('selected_features.json')\n",
    "    os.remove('selected_features.json')\n",
    "    \n",
    "    with open('dropped_features.json', 'w') as f:\n",
    "        json.dump({\n",
    "            'dropped_missing': dropped_missing,\n",
    "            'dropped_variance': dropped_variance,\n",
    "            'dropped_correlation': dropped_corr\n",
    "        }, f, indent=2)\n",
    "    mlflow.log_artifact('dropped_features.json')\n",
    "    os.remove('dropped_features.json')\n",
    "\n",
    "print(\"Logged XGBoost to MLflow\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dfe79a",
   "metadata": {},
   "source": [
    "### Generate Kaggle Submissions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b8180fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission files created:\n",
      "  phase1_bureau_lightgbm_v1.csv\n",
      "  phase1_bureau_xgboost_v1.csv\n",
      "\n",
      "LightGBM predictions - Min: 0.0029, Max: 0.9655, Mean: 0.3867\n",
      "XGBoost predictions  - Min: 0.0009, Max: 0.9774, Mean: 0.3486\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('../../data/raw/sample_submission.csv')\n",
    "\n",
    "lgb_preds = lgb_final.predict_proba(X_test_selected)[:, 1]\n",
    "xgb_preds = xgb_final.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "submission_lgb = sample_submission.copy()\n",
    "submission_lgb['TARGET'] = lgb_preds\n",
    "\n",
    "submission_xgb = sample_submission.copy()\n",
    "submission_xgb['TARGET'] = xgb_preds\n",
    "\n",
    "os.makedirs('../../data/submissions', exist_ok=True)\n",
    "\n",
    "submission_lgb.to_csv('../../data/submissions/phase1_bureau_lightgbm_v1.csv', index=False)\n",
    "submission_xgb.to_csv('../../data/submissions/phase1_bureau_xgboost_v1.csv', index=False)\n",
    "\n",
    "print(\"Submission files created:\")\n",
    "print(\"  phase1_bureau_lightgbm_v1.csv\")\n",
    "print(\"  phase1_bureau_xgboost_v1.csv\")\n",
    "\n",
    "print(f\"\\nLightGBM predictions - Min: {lgb_preds.min():.4f}, Max: {lgb_preds.max():.4f}, Mean: {lgb_preds.mean():.4f}\")\n",
    "print(f\"XGBoost predictions  - Min: {xgb_preds.min():.4f}, Max: {xgb_preds.max():.4f}, Mean: {xgb_preds.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e511c9",
   "metadata": {},
   "source": [
    "### Save Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "dbe74f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved to ../../models/phase1_bureau/\n",
      "  - lightgbm_v1.pkl\n",
      "  - xgboost_v1.pkl\n"
     ]
    }
   ],
   "source": [
    "output_model_dir = '../../models/phase1_bureau'\n",
    "os.makedirs(output_model_dir, exist_ok=True)\n",
    "\n",
    "model_artifacts_lgb = {\n",
    "    'model': lgb_final,\n",
    "    'selected_features': selected_features,\n",
    "    'categorical_features': CATEGORICAL_FEATURES,\n",
    "    'cat_mappings': cat_mappings,\n",
    "    'quick_val_auc': val_auc_lgb,\n",
    "    'cv_mean_auc': np.mean(lgb_cv_scores),\n",
    "    'cv_std_auc': np.std(lgb_cv_scores)\n",
    "}\n",
    "\n",
    "model_artifacts_xgb = {\n",
    "    'model': xgb_final,\n",
    "    'selected_features': selected_features,\n",
    "    'categorical_features': CATEGORICAL_FEATURES,\n",
    "    'cat_mappings': cat_mappings,\n",
    "    'quick_val_auc': val_auc_xgb,\n",
    "    'cv_mean_auc': np.mean(xgb_cv_scores),\n",
    "    'cv_std_auc': np.std(xgb_cv_scores)\n",
    "}\n",
    "\n",
    "joblib.dump(model_artifacts_lgb, f'{output_model_dir}/lightgbm_v1.pkl')\n",
    "joblib.dump(model_artifacts_xgb, f'{output_model_dir}/xgboost_v1.pkl')\n",
    "\n",
    "print(f\"Models saved to {output_model_dir}/\")\n",
    "print(f\"  - lightgbm_v1.pkl\")\n",
    "print(f\"  - xgboost_v1.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f159aa03",
   "metadata": {},
   "source": [
    "### Phase 1 Summary\n",
    "\n",
    "**Strategy:** Bureau credit history aggregations with Level 1 statistical filtering and Level 2 model-based importance selection.\n",
    "\n",
    "**Features Created:** 52 bureau features (DAYS_CREDIT patterns, AMT_CREDIT_SUM aggregations, CREDIT_ACTIVE/TYPE categories, derived ratios). Level 1 filtering: 52 → 36. Level 2 selection: Final 48 features (24 baseline + 24 bureau).\n",
    "\n",
    "**Results:** LightGBM Val 0.7665, CV 0.7543. XGBoost Val 0.7582, CV 0.7453. Kaggle: LightGBM Public 0.74795, XGBoost Private 0.74736/Public 0.73786.\n",
    "\n",
    "**Top Contributors:** DAYS_CREDIT patterns, AMT_CREDIT_SUM aggregations, debt_credit_ratio, active_closed_ratio, bureau_type_Microloan.\n",
    "\n",
    "**Saved:** Processed data and models to phase1_bureau/, tracked in MLflow, submissions generated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051d2046",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 2: Bureau Balance Features\n",
    "\n",
    "**Base:** Phase 1 selected features (48)\n",
    "\n",
    "Add monthly credit status patterns from bureau_balance.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595ecb8b",
   "metadata": {},
   "source": [
    "### Load Phase 1 Base Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e8c5a351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 Base Features: 48\n",
      "Phase 1 LightGBM CV AUC: 0.7543\n",
      "Phase 1 XGBoost CV AUC: 0.7453\n"
     ]
    }
   ],
   "source": [
    "with open('../../data/processed/phase1_bureau/feature_metadata.json', 'r') as f:\n",
    "    phase1_metadata = json.load(f)\n",
    "\n",
    "phase1_selected_features = phase1_metadata['feature_list']\n",
    "phase1_val_auc_lgb = phase1_metadata['cv_eval']['lgb_cv_mean']\n",
    "phase1_val_auc_xgb = phase1_metadata['cv_eval']['xgb_cv_mean']\n",
    "\n",
    "print(f\"Phase 1 Base Features: {len(phase1_selected_features)}\")\n",
    "print(f\"Phase 1 LightGBM CV AUC: {phase1_val_auc_lgb:.4f}\")\n",
    "print(f\"Phase 1 XGBoost CV AUC: {phase1_val_auc_xgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fbe9f7",
   "metadata": {},
   "source": [
    "### Bureau Balance Aggregations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9eaf68ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bureau Balance shape: (27299925, 3)\n",
      "Unique SK_ID_BUREAU: 817395\n",
      "Bureau Balance features created: 15\n"
     ]
    }
   ],
   "source": [
    "bb = pd.read_csv('../../data/raw/bureau_balance.csv')\n",
    "print(f\"Bureau Balance shape: {bb.shape}\")\n",
    "print(f\"Unique SK_ID_BUREAU: {bb['SK_ID_BUREAU'].nunique()}\")\n",
    "\n",
    "bb_agg = bb.groupby('SK_ID_BUREAU').agg({\n",
    "    'MONTHS_BALANCE': ['min', 'max', 'size']\n",
    "}).reset_index()\n",
    "bb_agg.columns = ['SK_ID_BUREAU', 'bb_months_balance_min', 'bb_months_balance_max', 'bb_months_balance_size']\n",
    "\n",
    "status_dummies = pd.get_dummies(bb['STATUS'], prefix='bb_status')\n",
    "bb_status = pd.concat([bb[['SK_ID_BUREAU']], status_dummies], axis=1)\n",
    "bb_status_agg = bb_status.groupby('SK_ID_BUREAU').sum().reset_index()\n",
    "\n",
    "bb_agg = bb_agg.merge(bb_status_agg, on='SK_ID_BUREAU', how='left')\n",
    "\n",
    "bureau_bb = bureau[['SK_ID_CURR', 'SK_ID_BUREAU']].merge(bb_agg, on='SK_ID_BUREAU', how='left')\n",
    "\n",
    "bb_features = bureau_bb.drop(columns=['SK_ID_BUREAU']).groupby('SK_ID_CURR').agg({\n",
    "    'bb_months_balance_min': ['min', 'mean'],\n",
    "    'bb_months_balance_max': ['max', 'mean'],\n",
    "    'bb_months_balance_size': ['sum', 'mean', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "bb_features.columns = ['SK_ID_CURR'] + ['_'.join(col).strip() for col in bb_features.columns[1:]]\n",
    "\n",
    "status_cols = [col for col in bureau_bb.columns if col.startswith('bb_status')]\n",
    "if status_cols:\n",
    "    bb_status_final = bureau_bb[['SK_ID_CURR'] + status_cols].groupby('SK_ID_CURR').sum().reset_index()\n",
    "    bb_features = bb_features.merge(bb_status_final, on='SK_ID_CURR', how='left')\n",
    "\n",
    "print(f\"Bureau Balance features created: {bb_features.shape[1] - 1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7926067",
   "metadata": {},
   "source": [
    "### Level 1 Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a9c6de9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering: 15 features\n",
      "Dropped 0 features (>80% missing)\n",
      "Dropped 0 features (low variance)\n",
      "Dropped 0 features (high correlation)\n",
      "\n",
      "After Level 1 filtering: 15 features\n"
     ]
    }
   ],
   "source": [
    "bb_features_only = bb_features.drop(columns=['SK_ID_CURR']).select_dtypes(include=[np.number])\n",
    "\n",
    "print(f\"Before filtering: {bb_features_only.shape[1]} features\")\n",
    "\n",
    "bb_features_only, bb_dropped_missing = filter_by_missing(bb_features_only, threshold=0.80)\n",
    "print(f\"Dropped {len(bb_dropped_missing)} features (>80% missing)\")\n",
    "\n",
    "bb_features_only, bb_dropped_variance = remove_low_variance(bb_features_only, threshold=0.01)\n",
    "print(f\"Dropped {len(bb_dropped_variance)} features (low variance)\")\n",
    "\n",
    "bb_features_only, bb_dropped_corr = remove_correlated(bb_features_only, threshold=0.95)\n",
    "print(f\"Dropped {len(bb_dropped_corr)} features (high correlation)\")\n",
    "\n",
    "print(f\"\\nAfter Level 1 filtering: {bb_features_only.shape[1]} features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df34e2fd",
   "metadata": {},
   "source": [
    "### Merge with Phase 1 Features + Train/Val/Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "5098ef49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (246008, 63)\n",
      "Val shape: (61503, 63)\n",
      "Test shape: (48744, 63)\n"
     ]
    }
   ],
   "source": [
    "bb_features_filtered = pd.concat([bb_features[['SK_ID_CURR']], bb_features_only], axis=1)\n",
    "\n",
    "X_train_phase2 = X_train_bureau[phase1_selected_features].copy()\n",
    "X_val_phase2 = X_val_bureau[phase1_selected_features].copy()\n",
    "\n",
    "X_test_with_bureau = pd.merge(\n",
    "    test_df[['SK_ID_CURR'] + BASELINE_FEATURES],\n",
    "    bureau_agg_filtered, on='SK_ID_CURR', how='left'\n",
    ").drop(columns=['SK_ID_CURR'])\n",
    "X_test_phase2 = X_test_with_bureau[phase1_selected_features].copy()\n",
    "\n",
    "train_ids = df.loc[X_train.index, 'SK_ID_CURR'].reset_index(drop=True)\n",
    "val_ids = df.loc[X_val.index, 'SK_ID_CURR'].reset_index(drop=True)\n",
    "test_ids = test_df['SK_ID_CURR'].reset_index(drop=True)\n",
    "\n",
    "X_train_bb = pd.merge(\n",
    "    pd.concat([train_ids, X_train_phase2.reset_index(drop=True)], axis=1),\n",
    "    bb_features_filtered, on='SK_ID_CURR', how='left'\n",
    ").drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "X_val_bb = pd.merge(\n",
    "    pd.concat([val_ids, X_val_phase2.reset_index(drop=True)], axis=1),\n",
    "    bb_features_filtered, on='SK_ID_CURR', how='left'\n",
    ").drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "X_test_bb = pd.merge(\n",
    "    pd.concat([test_ids, X_test_phase2.reset_index(drop=True)], axis=1),\n",
    "    bb_features_filtered, on='SK_ID_CURR', how='left'\n",
    ").drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "print(f\"Train shape: {X_train_bb.shape}\")\n",
    "print(f\"Val shape: {X_val_bb.shape}\")\n",
    "print(f\"Test shape: {X_test_bb.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e6bfdf",
   "metadata": {},
   "source": [
    "### Preliminary Training (for Level 2 Filtering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "0155de29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preliminary LightGBM Results:\n",
      "  Train AUC: 0.8041\n",
      "  Val AUC: 0.7640\n",
      "CPU times: total: 25.2 s\n",
      "Wall time: 3.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train_lgb_p2 = X_train_bb.copy()\n",
    "X_val_lgb_p2 = X_val_bb.copy()\n",
    "X_test_lgb_p2 = X_test_bb.copy()\n",
    "\n",
    "for col in CATEGORICAL_FEATURES:\n",
    "    if col in X_train_lgb_p2.columns:\n",
    "        X_train_lgb_p2[col] = X_train_lgb_p2[col].map(cat_mappings[col])\n",
    "        X_val_lgb_p2[col] = X_val_lgb_p2[col].map(cat_mappings[col])\n",
    "        X_test_lgb_p2[col] = X_test_lgb_p2[col].map(cat_mappings[col])\n",
    "\n",
    "lgb_bb_prelim = LGBMClassifier(\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_bb_prelim.fit(\n",
    "    X_train_lgb_p2, y_train,\n",
    "    eval_set=[(X_val_lgb_p2, y_val)],\n",
    "    eval_metric='auc'\n",
    ")\n",
    "\n",
    "train_auc_lgb_p2_prelim = roc_auc_score(y_train, lgb_bb_prelim.predict_proba(X_train_lgb_p2)[:, 1])\n",
    "val_auc_lgb_p2_prelim = roc_auc_score(y_val, lgb_bb_prelim.predict_proba(X_val_lgb_p2)[:, 1])\n",
    "\n",
    "print(\"Preliminary LightGBM Results:\")\n",
    "print(f\"  Train AUC: {train_auc_lgb_p2_prelim:.4f}\")\n",
    "print(f\"  Val AUC: {val_auc_lgb_p2_prelim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "92b9490c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preliminary XGBoost Results:\n",
      "  Train AUC: 0.9093\n",
      "  Val AUC: 0.7582\n",
      "CPU times: total: 5min 15s\n",
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb_bb_prelim = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    scale_pos_weight=11.4,\n",
    "    random_state=42,\n",
    "    tree_method='hist',\n",
    "    eval_metric='auc',\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb_bb_prelim.fit(\n",
    "    X_train_lgb_p2, y_train,\n",
    "    eval_set=[(X_val_lgb_p2, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "train_auc_xgb_p2_prelim = roc_auc_score(y_train, xgb_bb_prelim.predict_proba(X_train_lgb_p2)[:, 1])\n",
    "val_auc_xgb_p2_prelim = roc_auc_score(y_val, xgb_bb_prelim.predict_proba(X_val_lgb_p2)[:, 1])\n",
    "\n",
    "print(\"\\nPreliminary XGBoost Results:\")\n",
    "print(f\"  Train AUC: {train_auc_xgb_p2_prelim:.4f}\")\n",
    "print(f\"  Val AUC: {val_auc_xgb_p2_prelim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800db319",
   "metadata": {},
   "source": [
    "### Level 2 Filtering: Feature Importance Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e2dd2773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 LightGBM Importances:\n",
      "                           feature  importance\n",
      "7                     EXT_SOURCE_1         233\n",
      "31                    EXT_SOURCE_3         179\n",
      "32                    EXT_SOURCE_2         175\n",
      "27                      DAYS_BIRTH         157\n",
      "42                      AMT_CREDIT         149\n",
      "37                     AMT_ANNUITY         127\n",
      "8                  AMT_GOODS_PRICE         116\n",
      "1                    DAYS_EMPLOYED          93\n",
      "29  bureau_DAYS_CREDIT_ENDDATE_max          87\n",
      "9                  DAYS_ID_PUBLISH          79\n",
      "\n",
      "Top 10 XGBoost Importances:\n",
      "                     feature  importance\n",
      "31              EXT_SOURCE_3    0.065170\n",
      "32              EXT_SOURCE_2    0.057020\n",
      "36               CODE_GENDER    0.046176\n",
      "25       NAME_EDUCATION_TYPE    0.034258\n",
      "13        NAME_CONTRACT_TYPE    0.033505\n",
      "7               EXT_SOURCE_1    0.025308\n",
      "15              FLAG_OWN_CAR    0.024942\n",
      "16     bureau_type_Microloan    0.020835\n",
      "43          NAME_INCOME_TYPE    0.020273\n",
      "40  DEF_60_CNT_SOCIAL_CIRCLE    0.019542\n",
      "\n",
      "Threshold: 20\n",
      "LightGBM selected: 48\n",
      "XGBoost selected: 0\n",
      "Common features: 0\n",
      "Union features: 48\n",
      "\n",
      "Using UNION: 48 features selected\n"
     ]
    }
   ],
   "source": [
    "lgb_importances_p2 = get_feature_importances(lgb_bb_prelim, X_train_lgb_p2.columns.tolist())\n",
    "xgb_importances_p2 = get_feature_importances(xgb_bb_prelim, X_train_lgb_p2.columns.tolist())\n",
    "\n",
    "print(\"\\nTop 10 LightGBM Importances:\")\n",
    "print(lgb_importances_p2.head(10))\n",
    "\n",
    "print(\"\\nTop 10 XGBoost Importances:\")\n",
    "print(xgb_importances_p2.head(10))\n",
    "\n",
    "importance_threshold_p2 = 20\n",
    "lgb_selected_p2 = select_by_importance_threshold(lgb_importances_p2, importance_threshold_p2)\n",
    "xgb_selected_p2 = select_by_importance_threshold(xgb_importances_p2, importance_threshold_p2)\n",
    "\n",
    "common_p2 = list(set(lgb_selected_p2) & set(xgb_selected_p2))\n",
    "all_selected_p2 = list(set(lgb_selected_p2) | set(xgb_selected_p2))\n",
    "\n",
    "print(f\"\\nThreshold: {importance_threshold_p2}\")\n",
    "print(f\"LightGBM selected: {len(lgb_selected_p2)}\")\n",
    "print(f\"XGBoost selected: {len(xgb_selected_p2)}\")\n",
    "print(f\"Common features: {len(common_p2)}\")\n",
    "print(f\"Union features: {len(all_selected_p2)}\")\n",
    "\n",
    "selected_features_p2 = all_selected_p2\n",
    "print(f\"\\nUsing UNION: {len(selected_features_p2)} features selected\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc22fe60",
   "metadata": {},
   "source": [
    "### Final Model Training + Quick Evaluation + Cross-Validation + Saves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "dba7feab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features shape:\n",
      "  Train: (246008, 48)\n",
      "  Val: (61503, 48)\n",
      "  Test: (48744, 48)\n"
     ]
    }
   ],
   "source": [
    "X_train_selected_p2 = X_train_lgb_p2[selected_features_p2]\n",
    "X_val_selected_p2 = X_val_lgb_p2[selected_features_p2]\n",
    "X_test_selected_p2 = X_test_lgb_p2[selected_features_p2]\n",
    "\n",
    "print(f\"Selected features shape:\")\n",
    "print(f\"  Train: {X_train_selected_p2.shape}\")\n",
    "print(f\"  Val: {X_val_selected_p2.shape}\")\n",
    "print(f\"  Test: {X_test_selected_p2.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "511df059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final LightGBM Results:\n",
      "  Train AUC: 0.8448\n",
      "  Val AUC: 0.7664\n",
      "CPU times: total: 1min 14s\n",
      "Wall time: 9.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgb_final_p2 = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_final_p2.fit(\n",
    "    X_train_selected_p2, y_train,\n",
    "    eval_set=[(X_val_selected_p2, y_val)],\n",
    "    eval_metric='auc'\n",
    ")\n",
    "\n",
    "train_auc_lgb_p2 = roc_auc_score(y_train, lgb_final_p2.predict_proba(X_train_selected_p2)[:, 1])\n",
    "val_auc_lgb_p2 = roc_auc_score(y_val, lgb_final_p2.predict_proba(X_val_selected_p2)[:, 1])\n",
    "\n",
    "print(\"Final LightGBM Results:\")\n",
    "print(f\"  Train AUC: {train_auc_lgb_p2:.4f}\")\n",
    "print(f\"  Val AUC: {val_auc_lgb_p2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "47d2c8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final XGBoost Results:\n",
      "  Train AUC: 0.9100\n",
      "  Val AUC: 0.7591\n",
      "CPU times: total: 4min 22s\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb_final_p2 = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    scale_pos_weight=11.4,\n",
    "    random_state=42,\n",
    "    tree_method='hist',\n",
    "    eval_metric='auc',\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb_final_p2.fit(\n",
    "    X_train_selected_p2, y_train,\n",
    "    eval_set=[(X_val_selected_p2, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "train_auc_xgb_p2 = roc_auc_score(y_train, xgb_final_p2.predict_proba(X_train_selected_p2)[:, 1])\n",
    "val_auc_xgb_p2 = roc_auc_score(y_val, xgb_final_p2.predict_proba(X_val_selected_p2)[:, 1])\n",
    "\n",
    "print(\"\\nFinal XGBoost Results:\")\n",
    "print(f\"  Train AUC: {train_auc_xgb_p2:.4f}\")\n",
    "print(f\"  Val AUC: {val_auc_xgb_p2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "e7435ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "QUICK EVALUATION (80/20 Split - Phase 1 Comparison)\n",
      "============================================================\n",
      "Model                Train AUC    Val AUC      Improvement  Gap     \n",
      "------------------------------------------------------------\n",
      "Phase 1 LightGBM     -            0.7543       -            -       \n",
      "Phase 2 LightGBM     0.8448       0.7664       0.0122++++++ 0.0784  \n",
      "Phase 1 XGBoost      -            0.7453       -            -       \n",
      "Phase 2 XGBoost      0.9100       0.7591       0.0138++++++ 0.1510  \n",
      "============================================================\n",
      "\n",
      "Selected Features:\n",
      "  Total: 48\n",
      "  Phase 1: 46\n",
      "  Bureau Balance (new): 2\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"QUICK EVALUATION (80/20 Split - Phase 1 Comparison)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Model':<20} {'Train AUC':<12} {'Val AUC':<12} {'Improvement':<12} {'Gap':<8}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Phase 1 LightGBM':<20} {'-':<12} {phase1_val_auc_lgb:<12.4f} {'-':<12} {'-':<8}\")\n",
    "print(f\"{'Phase 2 LightGBM':<20} {train_auc_lgb_p2:<12.4f} {val_auc_lgb_p2:<12.4f} {val_auc_lgb_p2 - phase1_val_auc_lgb:+<12.4f} {train_auc_lgb_p2 - val_auc_lgb_p2:<8.4f}\")\n",
    "print(f\"{'Phase 1 XGBoost':<20} {'-':<12} {phase1_val_auc_xgb:<12.4f} {'-':<12} {'-':<8}\")\n",
    "print(f\"{'Phase 2 XGBoost':<20} {train_auc_xgb_p2:<12.4f} {val_auc_xgb_p2:<12.4f} {val_auc_xgb_p2 - phase1_val_auc_xgb:+<12.4f} {train_auc_xgb_p2 - val_auc_xgb_p2:<8.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "bb_new_features = [f for f in selected_features_p2 if f.startswith('bb_')]\n",
    "print(f\"\\nSelected Features:\")\n",
    "print(f\"  Total: {len(selected_features_p2)}\")\n",
    "print(f\"  Phase 1: {len([f for f in selected_features_p2 if f in phase1_selected_features])}\")\n",
    "print(f\"  Bureau Balance (new): {len(bb_new_features)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d0df7",
   "metadata": {},
   "source": [
    "### Cross-Validation (5-Fold StratifiedKFold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f4dd8091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Fold 1: LightGBM=0.7583, XGBoost=0.7483\n",
      "Fold 2: LightGBM=0.7520, XGBoost=0.7433\n",
      "Fold 3: LightGBM=0.7534, XGBoost=0.7435\n",
      "Fold 4: LightGBM=0.7542, XGBoost=0.7471\n",
      "Fold 5: LightGBM=0.7566, XGBoost=0.7470\n",
      "------------------------------------------------------------\n",
      "\n",
      "LightGBM CV: 0.7549 ± 0.0022\n",
      "XGBoost CV:  0.7458 ± 0.0021\n",
      "\n",
      "Phase 1 LightGBM CV: 0.7543\n",
      "Phase 1 XGBoost CV:  0.7453\n",
      "\n",
      "LightGBM Improvement: +0.0006\n",
      "XGBoost Improvement:  +0.0005\n",
      "CPU times: total: 25min 48s\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_full = pd.concat([X_train, X_val], axis=0).reset_index(drop=True)\n",
    "y_full = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    "\n",
    "X_full_with_bureau = pd.merge(\n",
    "    pd.concat([df.loc[X_full.index, 'SK_ID_CURR'].reset_index(drop=True), X_full], axis=1),\n",
    "    bureau_agg_filtered, on='SK_ID_CURR', how='left'\n",
    ").drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "X_full_phase2 = X_full_with_bureau[phase1_selected_features].copy()\n",
    "\n",
    "full_ids = pd.concat([df.loc[X_train.index, 'SK_ID_CURR'], df.loc[X_val.index, 'SK_ID_CURR']]).reset_index(drop=True)\n",
    "X_full_bb = pd.merge(\n",
    "    pd.concat([full_ids, X_full_phase2], axis=1),\n",
    "    bb_features_filtered, on='SK_ID_CURR', how='left'\n",
    ").drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "X_full_selected_p2 = X_full_bb[selected_features_p2].copy()\n",
    "for col in CATEGORICAL_FEATURES:\n",
    "    if col in X_full_selected_p2.columns:\n",
    "        X_full_selected_p2[col] = X_full_selected_p2[col].map(cat_mappings[col])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "lgb_cv_scores_p2 = []\n",
    "xgb_cv_scores_p2 = []\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_full_selected_p2, y_full), 1):\n",
    "    X_cv_train, X_cv_val = X_full_selected_p2.iloc[train_idx], X_full_selected_p2.iloc[val_idx]\n",
    "    y_cv_train, y_cv_val = y_full.iloc[train_idx], y_full.iloc[val_idx]\n",
    "    \n",
    "    lgb_cv = LGBMClassifier(\n",
    "        n_estimators=500, learning_rate=0.05, max_depth=7,\n",
    "        num_leaves=31, random_state=42, class_weight='balanced', verbose=-1\n",
    "    )\n",
    "    lgb_cv.fit(X_cv_train, y_cv_train, eval_set=[(X_cv_val, y_cv_val)], eval_metric='auc')\n",
    "    lgb_val_auc = roc_auc_score(y_cv_val, lgb_cv.predict_proba(X_cv_val)[:, 1])\n",
    "    lgb_cv_scores_p2.append(lgb_val_auc)\n",
    "    \n",
    "    xgb_cv = XGBClassifier(\n",
    "        n_estimators=500, learning_rate=0.05, max_depth=7,\n",
    "        scale_pos_weight=11.4, random_state=42, tree_method='hist',\n",
    "        eval_metric='auc', verbosity=0\n",
    "    )\n",
    "    xgb_cv.fit(X_cv_train, y_cv_train, eval_set=[(X_cv_val, y_cv_val)], verbose=False)\n",
    "    xgb_val_auc = roc_auc_score(y_cv_val, xgb_cv.predict_proba(X_cv_val)[:, 1])\n",
    "    xgb_cv_scores_p2.append(xgb_val_auc)\n",
    "    \n",
    "    print(f\"Fold {fold}: LightGBM={lgb_val_auc:.4f}, XGBoost={xgb_val_auc:.4f}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"\\nLightGBM CV: {np.mean(lgb_cv_scores_p2):.4f} ± {np.std(lgb_cv_scores_p2):.4f}\")\n",
    "print(f\"XGBoost CV:  {np.mean(xgb_cv_scores_p2):.4f} ± {np.std(xgb_cv_scores_p2):.4f}\")\n",
    "print(f\"\\nPhase 1 LightGBM CV: {phase1_val_auc_lgb:.4f}\")\n",
    "print(f\"Phase 1 XGBoost CV:  {phase1_val_auc_xgb:.4f}\")\n",
    "print(f\"\\nLightGBM Improvement: {np.mean(lgb_cv_scores_p2) - phase1_val_auc_lgb:+.4f}\")\n",
    "print(f\"XGBoost Improvement:  {np.mean(xgb_cv_scores_p2) - phase1_val_auc_xgb:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983b04c2",
   "metadata": {},
   "source": [
    "### Save Processed Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a491a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to ../../data/processed/phase2_bureau_balance/\n",
      "  - train_features.csv: (246008, 48)\n",
      "  - val_features.csv: (61503, 48)\n",
      "  - test_features.csv: (48744, 48)\n",
      "  - feature_metadata.json: 48 features\n"
     ]
    }
   ],
   "source": [
    "output_dir_p2 = '../../data/processed/phase2_bureau_balance'\n",
    "os.makedirs(output_dir_p2, exist_ok=True)\n",
    "\n",
    "train_ids = df.loc[X_train.index, 'SK_ID_CURR'].reset_index(drop=True)\n",
    "val_ids = df.loc[X_val.index, 'SK_ID_CURR'].reset_index(drop=True)\n",
    "test_ids = test_df['SK_ID_CURR'].reset_index(drop=True)\n",
    "\n",
    "pd.concat([train_ids, X_train_selected_p2.reset_index(drop=True)], axis=1).to_csv(\n",
    "    f'{output_dir_p2}/X_train.csv', index=False\n",
    ")\n",
    "pd.DataFrame(y_train).to_csv(f'{output_dir_p2}/y_train.csv', index=False)\n",
    "\n",
    "pd.concat([val_ids, X_val_selected_p2.reset_index(drop=True)], axis=1).to_csv(\n",
    "    f'{output_dir_p2}/X_val.csv', index=False\n",
    ")\n",
    "pd.DataFrame(y_val).to_csv(f'{output_dir_p2}/y_val.csv', index=False)\n",
    "\n",
    "pd.concat([test_ids, X_test_selected_p2.reset_index(drop=True)], axis=1).to_csv(\n",
    "    f'{output_dir_p2}/X_test.csv', index=False\n",
    ")\n",
    "\n",
    "feature_metadata_p2 = {\n",
    "    'phase': 'phase2_bureau_balance',\n",
    "    'base_phase': 'phase1_bureau',\n",
    "    'n_phase1_features': len(phase1_selected_features),\n",
    "    'n_bb_features_created': bb_features.shape[1] - 1,\n",
    "    'n_bb_features_after_level1': bb_features_only.shape[1],\n",
    "    'n_features_final': len(selected_features_p2),\n",
    "    'feature_list': selected_features_p2,\n",
    "    'phase1_features': [f for f in selected_features_p2 if f in phase1_selected_features],\n",
    "    'bb_features_new': bb_new_features,\n",
    "    'dropped_missing': bb_dropped_missing,\n",
    "    'dropped_variance': bb_dropped_variance,\n",
    "    'dropped_corr': bb_dropped_corr,\n",
    "    'importance_threshold': importance_threshold_p2,\n",
    "    'quick_eval': {\n",
    "        'lgb_val_auc': float(val_auc_lgb_p2),\n",
    "        'xgb_val_auc': float(val_auc_xgb_p2),\n",
    "        'lgb_improvement': float(val_auc_lgb_p2 - phase1_val_auc_lgb),\n",
    "        'xgb_improvement': float(val_auc_xgb_p2 - phase1_val_auc_xgb)\n",
    "    },\n",
    "    'cv_eval': {\n",
    "        'lgb_cv_mean': float(np.mean(lgb_cv_scores_p2)),\n",
    "        'lgb_cv_std': float(np.std(lgb_cv_scores_p2)),\n",
    "        'xgb_cv_mean': float(np.mean(xgb_cv_scores_p2)),\n",
    "        'xgb_cv_std': float(np.std(xgb_cv_scores_p2)),\n",
    "        'lgb_improvement_cv': float(np.mean(lgb_cv_scores_p2) - phase1_val_auc_lgb),\n",
    "        'xgb_improvement_cv': float(np.mean(xgb_cv_scores_p2) - phase1_val_auc_xgb)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f'{output_dir_p2}/feature_metadata.json', 'w') as f:\n",
    "    json.dump(feature_metadata_p2, f, indent=2)\n",
    "\n",
    "print(f\"Saved processed data to {output_dir_p2}/\")\n",
    "print(f\"  - train_features.csv: {X_train_selected_p2.shape}\")\n",
    "print(f\"  - val_features.csv: {X_val_selected_p2.shape}\")\n",
    "print(f\"  - test_features.csv: {X_test_selected_p2.shape}\")\n",
    "print(f\"  - feature_metadata.json: {len(selected_features_p2)} features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b2fd36",
   "metadata": {},
   "source": [
    "### MLflow Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "1c31b9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 22:31:39 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/12 22:31:44 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d058582bbf4366a236e9869683a426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged LightGBM to MLflow\n"
     ]
    }
   ],
   "source": [
    "mlflow_tracking_uri = os.path.join(os.getcwd(), 'mlruns')\n",
    "mlflow.set_tracking_uri(f\"file:///{mlflow_tracking_uri}\")\n",
    "mlflow.set_experiment(\"feature_engineering\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"phase2_bureau_balance_lightgbm\"):\n",
    "    mlflow.log_param(\"phase\", \"bureau_balance\")\n",
    "    mlflow.log_param(\"base_phase\", \"phase1_bureau\")\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM\")\n",
    "    mlflow.log_param(\"n_estimators\", 500)\n",
    "    mlflow.log_param(\"learning_rate\", 0.05)\n",
    "    mlflow.log_param(\"max_depth\", 7)\n",
    "    mlflow.log_param(\"n_phase1_features\", len(phase1_selected_features))\n",
    "    mlflow.log_param(\"n_bb_features_new\", len(bb_new_features))\n",
    "    mlflow.log_param(\"n_features_created\", bb_features.shape[1] - 1)\n",
    "    mlflow.log_param(\"n_features_after_level1\", bb_features_only.shape[1])\n",
    "    mlflow.log_param(\"n_features_final\", len(selected_features_p2))\n",
    "    mlflow.log_param(\"n_dropped_missing\", len(bb_dropped_missing))\n",
    "    mlflow.log_param(\"n_dropped_variance\", len(bb_dropped_variance))\n",
    "    mlflow.log_param(\"n_dropped_correlation\", len(bb_dropped_corr))\n",
    "    mlflow.log_param(\"importance_threshold\", importance_threshold_p2)\n",
    "    \n",
    "    mlflow.log_metric(\"quick_train_auc\", train_auc_lgb_p2)\n",
    "    mlflow.log_metric(\"quick_val_auc\", val_auc_lgb_p2)\n",
    "    mlflow.log_metric(\"cv_mean_auc\", np.mean(lgb_cv_scores_p2))\n",
    "    mlflow.log_metric(\"cv_std_auc\", np.std(lgb_cv_scores_p2))\n",
    "    mlflow.log_metric(\"phase1_val_auc\", phase1_val_auc_lgb)\n",
    "    mlflow.log_metric(\"improvement_quick\", val_auc_lgb_p2 - phase1_val_auc_lgb)\n",
    "    mlflow.log_metric(\"improvement_cv\", np.mean(lgb_cv_scores_p2) - phase1_val_auc_lgb)\n",
    "    mlflow.log_metric(\"train_val_gap\", train_auc_lgb_p2 - val_auc_lgb_p2)\n",
    "    \n",
    "    X_sample = X_train_selected_p2.iloc[:5].fillna(0)\n",
    "    y_sample = y_train.iloc[:5]\n",
    "    signature = mlflow.models.infer_signature(X_sample, y_sample)\n",
    "    \n",
    "    mlflow.sklearn.log_model(lgb_final_p2, \"model\", signature=signature, input_example=X_sample)\n",
    "    \n",
    "    lgb_importances_final_p2 = get_feature_importances(lgb_final_p2, selected_features_p2)\n",
    "    lgb_importances_final_p2.to_csv('feature_importance_lgb_p2.csv', index=False)\n",
    "    mlflow.log_artifact('feature_importance_lgb_p2.csv')\n",
    "    os.remove('feature_importance_lgb_p2.csv')\n",
    "    \n",
    "    with open('selected_features_p2.json', 'w') as f:\n",
    "        json.dump({'features': selected_features_p2}, f, indent=2)\n",
    "    mlflow.log_artifact('selected_features_p2.json')\n",
    "    os.remove('selected_features_p2.json')\n",
    "    \n",
    "    with open('dropped_features_p2.json', 'w') as f:\n",
    "        json.dump({\n",
    "            'dropped_missing': bb_dropped_missing,\n",
    "            'dropped_variance': bb_dropped_variance,\n",
    "            'dropped_correlation': bb_dropped_corr\n",
    "        }, f, indent=2)\n",
    "    mlflow.log_artifact('dropped_features_p2.json')\n",
    "    os.remove('dropped_features_p2.json')\n",
    "\n",
    "print(\"Logged LightGBM to MLflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "b9257efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 22:31:44 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/12 22:31:48 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e245ab310d964c0eb6e68e787ee4fca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged XGBoost to MLflow\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"phase2_bureau_balance_xgboost\"):\n",
    "    mlflow.log_param(\"phase\", \"bureau_balance\")\n",
    "    mlflow.log_param(\"base_phase\", \"phase1_bureau\")\n",
    "    mlflow.log_param(\"model_type\", \"XGBoost\")\n",
    "    mlflow.log_param(\"n_estimators\", 500)\n",
    "    mlflow.log_param(\"learning_rate\", 0.05)\n",
    "    mlflow.log_param(\"max_depth\", 7)\n",
    "    mlflow.log_param(\"n_phase1_features\", len(phase1_selected_features))\n",
    "    mlflow.log_param(\"n_bb_features_new\", len(bb_new_features))\n",
    "    mlflow.log_param(\"n_features_created\", bb_features.shape[1] - 1)\n",
    "    mlflow.log_param(\"n_features_after_level1\", bb_features_only.shape[1])\n",
    "    mlflow.log_param(\"n_features_final\", len(selected_features_p2))\n",
    "    mlflow.log_param(\"n_dropped_missing\", len(bb_dropped_missing))\n",
    "    mlflow.log_param(\"n_dropped_variance\", len(bb_dropped_variance))\n",
    "    mlflow.log_param(\"n_dropped_correlation\", len(bb_dropped_corr))\n",
    "    mlflow.log_param(\"importance_threshold\", importance_threshold_p2)\n",
    "    \n",
    "    mlflow.log_metric(\"quick_train_auc\", train_auc_xgb_p2)\n",
    "    mlflow.log_metric(\"quick_val_auc\", val_auc_xgb_p2)\n",
    "    mlflow.log_metric(\"cv_mean_auc\", np.mean(xgb_cv_scores_p2))\n",
    "    mlflow.log_metric(\"cv_std_auc\", np.std(xgb_cv_scores_p2))\n",
    "    mlflow.log_metric(\"phase1_val_auc\", phase1_val_auc_xgb)\n",
    "    mlflow.log_metric(\"improvement_quick\", val_auc_xgb_p2 - phase1_val_auc_xgb)\n",
    "    mlflow.log_metric(\"improvement_cv\", np.mean(xgb_cv_scores_p2) - phase1_val_auc_xgb)\n",
    "    mlflow.log_metric(\"train_val_gap\", train_auc_xgb_p2 - val_auc_xgb_p2)\n",
    "    \n",
    "    mlflow.sklearn.log_model(xgb_final_p2, \"model\", signature=signature, input_example=X_sample)\n",
    "    \n",
    "    xgb_importances_final_p2 = get_feature_importances(xgb_final_p2, selected_features_p2)\n",
    "    xgb_importances_final_p2.to_csv('feature_importance_xgb_p2.csv', index=False)\n",
    "    mlflow.log_artifact('feature_importance_xgb_p2.csv')\n",
    "    os.remove('feature_importance_xgb_p2.csv')\n",
    "    \n",
    "    with open('selected_features_p2.json', 'w') as f:\n",
    "        json.dump({'features': selected_features_p2}, f, indent=2)\n",
    "    mlflow.log_artifact('selected_features_p2.json')\n",
    "    os.remove('selected_features_p2.json')\n",
    "    \n",
    "    with open('dropped_features_p2.json', 'w') as f:\n",
    "        json.dump({\n",
    "            'dropped_missing': bb_dropped_missing,\n",
    "            'dropped_variance': bb_dropped_variance,\n",
    "            'dropped_correlation': bb_dropped_corr\n",
    "        }, f, indent=2)\n",
    "    mlflow.log_artifact('dropped_features_p2.json')\n",
    "    os.remove('dropped_features_p2.json')\n",
    "\n",
    "print(\"Logged XGBoost to MLflow\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c83b28",
   "metadata": {},
   "source": [
    "### Save Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6d093368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved to ../../models/phase2_bureau_balance/\n",
      "  - lightgbm_v1.pkl\n",
      "  - xgboost_v1.pkl\n"
     ]
    }
   ],
   "source": [
    "output_model_dir_p2 = '../../models/phase2_bureau_balance'\n",
    "os.makedirs(output_model_dir_p2, exist_ok=True)\n",
    "\n",
    "model_artifacts_lgb_p2 = {\n",
    "    'model': lgb_final_p2,\n",
    "    'selected_features': selected_features_p2,\n",
    "    'categorical_features': CATEGORICAL_FEATURES,\n",
    "    'cat_mappings': cat_mappings,\n",
    "    'quick_val_auc': val_auc_lgb_p2,\n",
    "    'cv_mean_auc': np.mean(lgb_cv_scores_p2),\n",
    "    'cv_std_auc': np.std(lgb_cv_scores_p2),\n",
    "    'phase1_val_auc': phase1_val_auc_lgb,\n",
    "    'improvement': val_auc_lgb_p2 - phase1_val_auc_lgb\n",
    "}\n",
    "\n",
    "model_artifacts_xgb_p2 = {\n",
    "    'model': xgb_final_p2,\n",
    "    'selected_features': selected_features_p2,\n",
    "    'categorical_features': CATEGORICAL_FEATURES,\n",
    "    'cat_mappings': cat_mappings,\n",
    "    'quick_val_auc': val_auc_xgb_p2,\n",
    "    'cv_mean_auc': np.mean(xgb_cv_scores_p2),\n",
    "    'cv_std_auc': np.std(xgb_cv_scores_p2),\n",
    "    'phase1_val_auc': phase1_val_auc_xgb,\n",
    "    'improvement': val_auc_xgb_p2 - phase1_val_auc_xgb\n",
    "}\n",
    "\n",
    "joblib.dump(model_artifacts_lgb_p2, f'{output_model_dir_p2}/lightgbm_v1.pkl')\n",
    "joblib.dump(model_artifacts_xgb_p2, f'{output_model_dir_p2}/xgboost_v1.pkl')\n",
    "\n",
    "print(f\"Models saved to {output_model_dir_p2}/\")\n",
    "print(f\"  - lightgbm_v1.pkl\")\n",
    "print(f\"  - xgboost_v1.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907cf476",
   "metadata": {},
   "source": [
    "### Generate Kaggle Submissions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c8a975b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission files created:\n",
      "  phase2_bureau_balance_lightgbm_v1.csv\n",
      "  phase2_bureau_balance_xgboost_v1.csv\n",
      "\n",
      "LightGBM predictions - Min: 0.0045, Max: 0.9661, Mean: 0.3758\n",
      "XGBoost predictions  - Min: 0.0015, Max: 0.9817, Mean: 0.3368\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('../../data/raw/sample_submission.csv')\n",
    "\n",
    "lgb_preds_p2 = lgb_final_p2.predict_proba(X_test_selected_p2)[:, 1]\n",
    "xgb_preds_p2 = xgb_final_p2.predict_proba(X_test_selected_p2)[:, 1]\n",
    "\n",
    "submission_lgb_p2 = sample_submission.copy()\n",
    "submission_lgb_p2['TARGET'] = lgb_preds_p2\n",
    "\n",
    "submission_xgb_p2 = sample_submission.copy()\n",
    "submission_xgb_p2['TARGET'] = xgb_preds_p2\n",
    "\n",
    "os.makedirs('../../data/submissions', exist_ok=True)\n",
    "\n",
    "submission_lgb_p2.to_csv('../../data/submissions/phase2_bureau_balance_lightgbm_v1.csv', index=False)\n",
    "submission_xgb_p2.to_csv('../../data/submissions/phase2_bureau_balance_xgboost_v1.csv', index=False)\n",
    "\n",
    "print(\"Submission files created:\")\n",
    "print(\"  phase2_bureau_balance_lightgbm_v1.csv\")\n",
    "print(\"  phase2_bureau_balance_xgboost_v1.csv\")\n",
    "\n",
    "print(f\"\\nLightGBM predictions - Min: {lgb_preds_p2.min():.4f}, Max: {lgb_preds_p2.max():.4f}, Mean: {lgb_preds_p2.mean():.4f}\")\n",
    "print(f\"XGBoost predictions  - Min: {xgb_preds_p2.min():.4f}, Max: {xgb_preds_p2.max():.4f}, Mean: {xgb_preds_p2.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f47294",
   "metadata": {},
   "source": [
    "### Phase 2 Summary\n",
    "\n",
    "**Strategy:** Bureau Balance monthly status patterns linked through bureau table, with minimal incremental gain.\n",
    "\n",
    "**Features Created:** 17-20 bureau_balance features (MONTHS_BALANCE aggregations, STATUS categories via OneHotEncoder). Level 1 filtering: No drops. Level 2 selection: Only 2 new features passed (bb_months_balance_size_mean, bb_status_1). Final: 48 features total.\n",
    "\n",
    "**Results:** LightGBM Val 0.7664, CV 0.7549 (+0.0006 from Phase 1). XGBoost Val 0.7591, CV 0.7458. Kaggle: LightGBM Private 0.75467/Public 0.74934, XGBoost Private 0.74857/Public 0.73306.\n",
    "\n",
    "**Top Contributors:** bb_months_balance_size_mean, bb_status_1. Most STATUS categories filtered out due to low variance.\n",
    "\n",
    "**Insight:** Minimal impact phase. Bureau Balance added limited value. XGBoost overfitting worsened.\n",
    "\n",
    "**Saved:** Processed data and models to phase2_bureau_balance/, tracked in MLflow, submissions generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b69e85",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 3: Previous Application Features\n",
    "\n",
    "**Base:** Phase 2 selected features (48)\n",
    "\n",
    "Add Home Credit application history patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac413ee",
   "metadata": {},
   "source": [
    "### Load Phase 2 Base Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "e6441e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 2 Base Features: 48\n",
      "Phase 2 LightGBM CV AUC: 0.7549\n"
     ]
    }
   ],
   "source": [
    "with open('../../data/processed/phase2_bureau_balance/feature_metadata.json', 'r') as f:\n",
    "    phase2_metadata = json.load(f)\n",
    "\n",
    "phase2_selected_features = phase2_metadata['feature_list']\n",
    "phase2_val_auc_lgb = phase2_metadata['cv_eval']['lgb_cv_mean']\n",
    "\n",
    "print(f\"Phase 2 Base Features: {len(phase2_selected_features)}\")\n",
    "print(f\"Phase 2 LightGBM CV AUC: {phase2_val_auc_lgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d3e841",
   "metadata": {},
   "source": [
    "### Previous Application Aggregations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "ff076920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Application shape: (1670214, 37)\n",
      "Unique SK_ID_CURR: 338857\n",
      "Previous Application aggregated features: 29\n"
     ]
    }
   ],
   "source": [
    "prev = pd.read_csv('../../data/raw/previous_application.csv')\n",
    "print(f\"Previous Application shape: {prev.shape}\")\n",
    "print(f\"Unique SK_ID_CURR: {prev['SK_ID_CURR'].nunique()}\")\n",
    "\n",
    "prev_agg = prev.groupby('SK_ID_CURR').agg({\n",
    "    'AMT_ANNUITY': ['min', 'max', 'mean', 'std'],\n",
    "    'AMT_APPLICATION': ['min', 'max', 'mean', 'std', 'sum'],\n",
    "    'AMT_CREDIT': ['min', 'max', 'mean', 'std', 'sum'],\n",
    "    'AMT_GOODS_PRICE': ['min', 'max', 'mean', 'std'],\n",
    "    'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "    'DAYS_DECISION': ['min', 'max', 'mean', 'std'],\n",
    "    'CNT_PAYMENT': ['min', 'max', 'mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "prev_agg.columns = ['SK_ID_CURR'] + [f'prev_{col[0]}_{col[1]}' for col in prev_agg.columns[1:]]\n",
    "\n",
    "print(f\"Previous Application aggregated features: {prev_agg.shape[1] - 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "4543496c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features with categorical and derived: 40\n"
     ]
    }
   ],
   "source": [
    "prev_status = aggregate_categorical_ohe(prev, 'SK_ID_CURR', 'NAME_CONTRACT_STATUS', 'prev_status')\n",
    "prev_type = aggregate_categorical_ohe(prev, 'SK_ID_CURR', 'NAME_CONTRACT_TYPE', 'prev_type')\n",
    "\n",
    "prev_agg = prev_agg.merge(prev_status, on='SK_ID_CURR', how='left')\n",
    "prev_agg = prev_agg.merge(prev_type, on='SK_ID_CURR', how='left')\n",
    "\n",
    "if 'prev_status_Approved' in prev_agg.columns and 'prev_status_Refused' in prev_agg.columns:\n",
    "    prev_agg['prev_approval_rate'] = prev_agg['prev_status_Approved'] / (prev_agg['prev_status_Approved'] + prev_agg['prev_status_Refused'] + 1)\n",
    "\n",
    "prev_agg['prev_app_credit_diff'] = (prev_agg['prev_AMT_APPLICATION_mean'] - prev_agg['prev_AMT_CREDIT_mean']) / (prev_agg['prev_AMT_APPLICATION_mean'] + 1)\n",
    "prev_agg['prev_app_count'] = prev.groupby('SK_ID_CURR').size().values\n",
    "\n",
    "print(f\"Total features with categorical and derived: {prev_agg.shape[1] - 1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c88350",
   "metadata": {},
   "source": [
    "### Level 1 Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "aac62cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering: 40 features\n",
      "Dropped 0 features (>80% missing)\n",
      "Dropped 1 features (low variance)\n",
      "Dropped 7 features (high correlation)\n",
      "\n",
      "After Level 1 filtering: 32 features\n"
     ]
    }
   ],
   "source": [
    "prev_features = prev_agg.drop(columns=['SK_ID_CURR']).select_dtypes(include=[np.number])\n",
    "\n",
    "print(f\"Before filtering: {prev_features.shape[1]} features\")\n",
    "\n",
    "prev_features, prev_dropped_missing = filter_by_missing(prev_features, threshold=0.80)\n",
    "print(f\"Dropped {len(prev_dropped_missing)} features (>80% missing)\")\n",
    "\n",
    "prev_features, prev_dropped_variance = remove_low_variance(prev_features, threshold=0.01)\n",
    "print(f\"Dropped {len(prev_dropped_variance)} features (low variance)\")\n",
    "\n",
    "prev_features, prev_dropped_corr = remove_correlated(prev_features, threshold=0.95)\n",
    "print(f\"Dropped {len(prev_dropped_corr)} features (high correlation)\")\n",
    "\n",
    "print(f\"\\nAfter Level 1 filtering: {prev_features.shape[1]} features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc21a71",
   "metadata": {},
   "source": [
    "### Merge with Phase 2 Features + Train/Val/Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2ef19772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (246008, 80)\n",
      "Val shape: (61503, 80)\n",
      "Test shape: (48744, 80)\n"
     ]
    }
   ],
   "source": [
    "prev_agg_filtered = pd.concat([prev_agg[['SK_ID_CURR']], prev_features], axis=1)\n",
    "\n",
    "X_train_with_bureau_bb = pd.merge(\n",
    "    pd.concat([df.loc[X_train.index, 'SK_ID_CURR'].reset_index(drop=True), X_train.reset_index(drop=True)], axis=1),\n",
    "    bureau_agg_filtered, on='SK_ID_CURR', how='left'\n",
    ")\n",
    "X_train_with_bureau_bb = pd.merge(\n",
    "    X_train_with_bureau_bb,\n",
    "    bb_features_filtered, on='SK_ID_CURR', how='left'\n",
    ").drop(columns=['SK_ID_CURR'])\n",
    "X_train_phase3 = X_train_with_bureau_bb[phase2_selected_features].copy()\n",
    "\n",
    "X_val_with_bureau_bb = pd.merge(\n",
    "    pd.concat([df.loc[X_val.index, 'SK_ID_CURR'].reset_index(drop=True), X_val.reset_index(drop=True)], axis=1),\n",
    "    bureau_agg_filtered, on='SK_ID_CURR', how='left'\n",
    ")\n",
    "X_val_with_bureau_bb = pd.merge(\n",
    "    X_val_with_bureau_bb,\n",
    "    bb_features_filtered, on='SK_ID_CURR', how='left'\n",
    ").drop(columns=['SK_ID_CURR'])\n",
    "X_val_phase3 = X_val_with_bureau_bb[phase2_selected_features].copy()\n",
    "\n",
    "X_test_with_bureau_bb = pd.merge(\n",
    "    test_df[['SK_ID_CURR'] + BASELINE_FEATURES],\n",
    "    bureau_agg_filtered, on='SK_ID_CURR', how='left'\n",
    ")\n",
    "X_test_with_bureau_bb = pd.merge(\n",
    "    X_test_with_bureau_bb,\n",
    "    bb_features_filtered, on='SK_ID_CURR', how='left'\n",
    ").drop(columns=['SK_ID_CURR'])\n",
    "X_test_phase3 = X_test_with_bureau_bb[phase2_selected_features].copy()\n",
    "\n",
    "train_ids = df.loc[X_train.index, 'SK_ID_CURR'].reset_index(drop=True)\n",
    "val_ids = df.loc[X_val.index, 'SK_ID_CURR'].reset_index(drop=True)\n",
    "test_ids = test_df['SK_ID_CURR'].reset_index(drop=True)\n",
    "\n",
    "X_train_prev = pd.merge(\n",
    "    pd.concat([train_ids, X_train_phase3.reset_index(drop=True)], axis=1),\n",
    "    prev_agg_filtered, on='SK_ID_CURR', how='left'\n",
    ").drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "X_val_prev = pd.merge(\n",
    "    pd.concat([val_ids, X_val_phase3.reset_index(drop=True)], axis=1),\n",
    "    prev_agg_filtered, on='SK_ID_CURR', how='left'\n",
    ").drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "X_test_prev = pd.merge(\n",
    "    pd.concat([test_ids, X_test_phase3.reset_index(drop=True)], axis=1),\n",
    "    prev_agg_filtered, on='SK_ID_CURR', how='left'\n",
    ").drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "print(f\"Train shape: {X_train_prev.shape}\")\n",
    "print(f\"Val shape: {X_val_prev.shape}\")\n",
    "print(f\"Test shape: {X_test_prev.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345d7d0c",
   "metadata": {},
   "source": [
    "### Preliminary Training (for Level 2 Filtering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b7cf5846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preliminary LightGBM Results:\n",
      "  Train AUC: 0.8140\n",
      "  Val AUC: 0.7722\n",
      "\n",
      "Preliminary XGBoost Results:\n",
      "  Train AUC: 0.8908\n",
      "  Val AUC: 0.7570\n"
     ]
    }
   ],
   "source": [
    "X_train_lgb_p3 = X_train_prev.copy()\n",
    "X_val_lgb_p3 = X_val_prev.copy()\n",
    "X_test_lgb_p3 = X_test_prev.copy()\n",
    "\n",
    "for col in CATEGORICAL_FEATURES:\n",
    "    if col in X_train_lgb_p3.columns:\n",
    "        X_train_lgb_p3[col] = X_train_lgb_p3[col].map(cat_mappings[col])\n",
    "        X_val_lgb_p3[col] = X_val_lgb_p3[col].map(cat_mappings[col])\n",
    "        X_test_lgb_p3[col] = X_test_lgb_p3[col].map(cat_mappings[col])\n",
    "\n",
    "lgb_prev_prelim = LGBMClassifier(\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_prev_prelim.fit(\n",
    "    X_train_lgb_p3, y_train,\n",
    "    eval_set=[(X_val_lgb_p3, y_val)],\n",
    "    eval_metric='auc'\n",
    ")\n",
    "\n",
    "train_auc_lgb_p3_prelim = roc_auc_score(y_train, lgb_prev_prelim.predict_proba(X_train_lgb_p3)[:, 1])\n",
    "val_auc_lgb_p3_prelim = roc_auc_score(y_val, lgb_prev_prelim.predict_proba(X_val_lgb_p3)[:, 1])\n",
    "\n",
    "print(\"Preliminary LightGBM Results:\")\n",
    "print(f\"  Train AUC: {train_auc_lgb_p3_prelim:.4f}\")\n",
    "print(f\"  Val AUC: {val_auc_lgb_p3_prelim:.4f}\")\n",
    "\n",
    "scale_pos_weight_p3 = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "xgb_prev_prelim = XGBClassifier(\n",
    "    random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight_p3,\n",
    "    eval_metric='auc',\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb_prev_prelim.fit(\n",
    "    X_train_lgb_p3, y_train,\n",
    "    eval_set=[(X_val_lgb_p3, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "train_auc_xgb_p3_prelim = roc_auc_score(y_train, xgb_prev_prelim.predict_proba(X_train_lgb_p3)[:, 1])\n",
    "val_auc_xgb_p3_prelim = roc_auc_score(y_val, xgb_prev_prelim.predict_proba(X_val_lgb_p3)[:, 1])\n",
    "\n",
    "print(\"\\nPreliminary XGBoost Results:\")\n",
    "print(f\"  Train AUC: {train_auc_xgb_p3_prelim:.4f}\")\n",
    "print(f\"  Val AUC: {val_auc_xgb_p3_prelim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b0485a",
   "metadata": {},
   "source": [
    "### Level 2 Filtering: Feature Importance Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "379e1280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 LightGBM Importances:\n",
      "                               feature  importance\n",
      "7                         EXT_SOURCE_1         188\n",
      "33                        EXT_SOURCE_2         154\n",
      "32                        EXT_SOURCE_3         129\n",
      "28                          DAYS_BIRTH         126\n",
      "38                         AMT_ANNUITY         116\n",
      "43                          AMT_CREDIT         107\n",
      "1                        DAYS_EMPLOYED          79\n",
      "8                      AMT_GOODS_PRICE          76\n",
      "77                  prev_approval_rate          73\n",
      "30      bureau_DAYS_CREDIT_ENDDATE_max          72\n",
      "50               prev_AMT_ANNUITY_mean          70\n",
      "69                prev_CNT_PAYMENT_std          70\n",
      "78                prev_app_credit_diff          69\n",
      "9                      DAYS_ID_PUBLISH          61\n",
      "10  bureau_AMT_CREDIT_MAX_OVERDUE_mean          61\n",
      "\n",
      "Top 15 XGBoost Importances:\n",
      "                     feature  importance\n",
      "32              EXT_SOURCE_3    0.059032\n",
      "33              EXT_SOURCE_2    0.055702\n",
      "37               CODE_GENDER    0.050783\n",
      "13        NAME_CONTRACT_TYPE    0.029793\n",
      "15              FLAG_OWN_CAR    0.029519\n",
      "26       NAME_EDUCATION_TYPE    0.027898\n",
      "44          NAME_INCOME_TYPE    0.026345\n",
      "7               EXT_SOURCE_1    0.021340\n",
      "77        prev_approval_rate    0.019943\n",
      "20  bureau_debt_credit_ratio    0.018576\n",
      "69      prev_CNT_PAYMENT_std    0.016235\n",
      "43                AMT_CREDIT    0.015974\n",
      "16     bureau_type_Microloan    0.015475\n",
      "8            AMT_GOODS_PRICE    0.014864\n",
      "1              DAYS_EMPLOYED    0.014260\n",
      "\n",
      "Threshold: 20\n",
      "LightGBM selected: 55\n",
      "XGBoost selected: 0\n",
      "\n",
      "Total features selected (union): 55\n"
     ]
    }
   ],
   "source": [
    "lgb_importances_p3 = get_feature_importances(lgb_prev_prelim, X_train_lgb_p3.columns.tolist())\n",
    "xgb_importances_p3 = get_feature_importances(xgb_prev_prelim, X_train_lgb_p3.columns.tolist())\n",
    "\n",
    "print(\"\\nTop 15 LightGBM Importances:\")\n",
    "print(lgb_importances_p3.head(15))\n",
    "\n",
    "print(\"\\nTop 15 XGBoost Importances:\")\n",
    "print(xgb_importances_p3.head(15))\n",
    "\n",
    "importance_threshold_p3 = 20\n",
    "lgb_selected_p3 = select_by_importance_threshold(lgb_importances_p3, importance_threshold_p3)\n",
    "xgb_selected_p3 = select_by_importance_threshold(xgb_importances_p3, importance_threshold_p3)\n",
    "\n",
    "print(f\"\\nThreshold: {importance_threshold_p3}\")\n",
    "print(f\"LightGBM selected: {len(lgb_selected_p3)}\")\n",
    "print(f\"XGBoost selected: {len(xgb_selected_p3)}\")\n",
    "\n",
    "selected_features_p3 = sorted(list(set(lgb_selected_p3 + xgb_selected_p3)))\n",
    "print(f\"\\nTotal features selected (union): {len(selected_features_p3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb284453",
   "metadata": {},
   "source": [
    "### Final Model Training (with selected features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "18bf5f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features shape:\n",
      "  Train: (246008, 55)\n",
      "  Val: (61503, 55)\n",
      "  Test: (48744, 55)\n"
     ]
    }
   ],
   "source": [
    "X_train_selected_p3 = X_train_lgb_p3[selected_features_p3]\n",
    "X_val_selected_p3 = X_val_lgb_p3[selected_features_p3]\n",
    "X_test_selected_p3 = X_test_lgb_p3[selected_features_p3]\n",
    "\n",
    "print(f\"Selected features shape:\")\n",
    "print(f\"  Train: {X_train_selected_p3.shape}\")\n",
    "print(f\"  Val: {X_val_selected_p3.shape}\")\n",
    "print(f\"  Test: {X_test_selected_p3.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "58496d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final LightGBM Results:\n",
      "  Train AUC: 0.8556\n",
      "  Val AUC: 0.7720\n",
      "\n",
      "Final XGBoost Results:\n",
      "  Train AUC: 0.9278\n",
      "  Val AUC: 0.7652\n",
      "CPU times: total: 6min 10s\n",
      "Wall time: 33.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgb_final_p3 = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_final_p3.fit(\n",
    "    X_train_selected_p3, y_train,\n",
    "    eval_set=[(X_val_selected_p3, y_val)],\n",
    "    eval_metric='auc'\n",
    ")\n",
    "\n",
    "train_auc_lgb_p3 = roc_auc_score(y_train, lgb_final_p3.predict_proba(X_train_selected_p3)[:, 1])\n",
    "val_auc_lgb_p3 = roc_auc_score(y_val, lgb_final_p3.predict_proba(X_val_selected_p3)[:, 1])\n",
    "\n",
    "print(\"Final LightGBM Results:\")\n",
    "print(f\"  Train AUC: {train_auc_lgb_p3:.4f}\")\n",
    "print(f\"  Val AUC: {val_auc_lgb_p3:.4f}\")\n",
    "\n",
    "xgb_final_p3 = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight_p3,\n",
    "    eval_metric='auc',\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb_final_p3.fit(\n",
    "    X_train_selected_p3, y_train,\n",
    "    eval_set=[(X_val_selected_p3, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "train_auc_xgb_p3 = roc_auc_score(y_train, xgb_final_p3.predict_proba(X_train_selected_p3)[:, 1])\n",
    "val_auc_xgb_p3 = roc_auc_score(y_val, xgb_final_p3.predict_proba(X_val_selected_p3)[:, 1])\n",
    "\n",
    "print(\"\\nFinal XGBoost Results:\")\n",
    "print(f\"  Train AUC: {train_auc_xgb_p3:.4f}\")\n",
    "print(f\"  Val AUC: {val_auc_xgb_p3:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "6701fcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "QUICK EVALUATION (80/20 Split - Phase 2 Comparison)\n",
      "======================================================================\n",
      "Model                     Train AUC    Val AUC      Improvement  Gap       \n",
      "----------------------------------------------------------------------\n",
      "Phase 2 LightGBM          -            0.7549       -            -         \n",
      "Phase 3 LightGBM          0.8556       0.7720       0.0171++++++ 0.0837    \n",
      "Phase 3 XGBoost           0.9278       0.7652       0.0103++++++ 0.1627    \n",
      "======================================================================\n",
      "\n",
      "Selected Features:\n",
      "  Total: 55\n",
      "  Phase 2: 40\n",
      "  Previous Application (new): 15\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"QUICK EVALUATION (80/20 Split - Phase 2 Comparison)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Model':<25} {'Train AUC':<12} {'Val AUC':<12} {'Improvement':<12} {'Gap':<10}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Phase 2 LightGBM':<25} {'-':<12} {phase2_val_auc_lgb:<12.4f} {'-':<12} {'-':<10}\")\n",
    "print(f\"{'Phase 3 LightGBM':<25} {train_auc_lgb_p3:<12.4f} {val_auc_lgb_p3:<12.4f} {val_auc_lgb_p3 - phase2_val_auc_lgb:+<12.4f} {train_auc_lgb_p3 - val_auc_lgb_p3:<10.4f}\")\n",
    "print(f\"{'Phase 3 XGBoost':<25} {train_auc_xgb_p3:<12.4f} {val_auc_xgb_p3:<12.4f} {val_auc_xgb_p3 - phase2_val_auc_lgb:+<12.4f} {train_auc_xgb_p3 - val_auc_xgb_p3:<10.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "prev_new_features = [f for f in selected_features_p3 if f.startswith('prev_')]\n",
    "print(f\"\\nSelected Features:\")\n",
    "print(f\"  Total: {len(selected_features_p3)}\")\n",
    "print(f\"  Phase 2: {len([f for f in selected_features_p3 if f in phase2_selected_features])}\")\n",
    "print(f\"  Previous Application (new): {len(prev_new_features)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56693826",
   "metadata": {},
   "source": [
    "### Cross-Validation + Save Data + MLflow + Save Models + Submissions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7251433c",
   "metadata": {},
   "source": [
    "### Cross-Validation (5-Fold StratifiedKFold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "cc34746b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Fold 1: LightGBM=0.7752  XGBoost=0.7687\n",
      "Fold 2: LightGBM=0.7678  XGBoost=0.7616\n",
      "Fold 3: LightGBM=0.7704  XGBoost=0.7652\n",
      "Fold 4: LightGBM=0.7692  XGBoost=0.7609\n",
      "Fold 5: LightGBM=0.7722  XGBoost=0.7639\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "LightGBM CV: 0.7710 ± 0.0026\n",
      "XGBoost CV:  0.7641 ± 0.0028\n",
      "\n",
      "Phase 2 LightGBM CV: 0.7549\n",
      "LightGBM Improvement: +0.0161\n",
      "XGBoost Improvement:  +0.0092\n",
      "CPU times: total: 30min 8s\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_full = pd.concat([X_train, X_val], axis=0).reset_index(drop=True)\n",
    "y_full = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    "\n",
    "full_ids = pd.concat([df.loc[X_train.index, 'SK_ID_CURR'], df.loc[X_val.index, 'SK_ID_CURR']]).reset_index(drop=True)\n",
    "\n",
    "X_full_with_all = pd.merge(\n",
    "    pd.concat([full_ids, X_full], axis=1),\n",
    "    bureau_agg_filtered, on='SK_ID_CURR', how='left'\n",
    ")\n",
    "X_full_with_all = pd.merge(\n",
    "    X_full_with_all,\n",
    "    bb_features_filtered, on='SK_ID_CURR', how='left'\n",
    ")\n",
    "X_full_with_all = pd.merge(\n",
    "    X_full_with_all,\n",
    "    prev_agg_filtered, on='SK_ID_CURR', how='left'\n",
    ").drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "X_full_selected_p3 = X_full_with_all[selected_features_p3].copy()\n",
    "for col in CATEGORICAL_FEATURES:\n",
    "    if col in X_full_selected_p3.columns:\n",
    "        X_full_selected_p3[col] = X_full_selected_p3[col].map(cat_mappings[col])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "lgb_cv_scores_p3 = []\n",
    "xgb_cv_scores_p3 = []\n",
    "\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_full_selected_p3, y_full), 1):\n",
    "    X_cv_train, X_cv_val = X_full_selected_p3.iloc[train_idx], X_full_selected_p3.iloc[val_idx]\n",
    "    y_cv_train, y_cv_val = y_full.iloc[train_idx], y_full.iloc[val_idx]\n",
    "    \n",
    "    lgb_cv = LGBMClassifier(\n",
    "        n_estimators=500, learning_rate=0.05, max_depth=7,\n",
    "        num_leaves=31, random_state=42, class_weight='balanced', verbose=-1\n",
    "    )\n",
    "    lgb_cv.fit(X_cv_train, y_cv_train, eval_set=[(X_cv_val, y_cv_val)], eval_metric='auc')\n",
    "    lgb_val_auc = roc_auc_score(y_cv_val, lgb_cv.predict_proba(X_cv_val)[:, 1])\n",
    "    lgb_cv_scores_p3.append(lgb_val_auc)\n",
    "    \n",
    "    scale_pos_weight_cv = len(y_cv_train[y_cv_train == 0]) / len(y_cv_train[y_cv_train == 1])\n",
    "    xgb_cv = XGBClassifier(\n",
    "        n_estimators=500, learning_rate=0.05, max_depth=7,\n",
    "        random_state=42, scale_pos_weight=scale_pos_weight_cv,\n",
    "        eval_metric='auc', verbosity=0\n",
    "    )\n",
    "    xgb_cv.fit(X_cv_train, y_cv_train, eval_set=[(X_cv_val, y_cv_val)], verbose=False)\n",
    "    xgb_val_auc = roc_auc_score(y_cv_val, xgb_cv.predict_proba(X_cv_val)[:, 1])\n",
    "    xgb_cv_scores_p3.append(xgb_val_auc)\n",
    "    \n",
    "    print(f\"Fold {fold}: LightGBM={lgb_val_auc:.4f}  XGBoost={xgb_val_auc:.4f}\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"\\nLightGBM CV: {np.mean(lgb_cv_scores_p3):.4f} ± {np.std(lgb_cv_scores_p3):.4f}\")\n",
    "print(f\"XGBoost CV:  {np.mean(xgb_cv_scores_p3):.4f} ± {np.std(xgb_cv_scores_p3):.4f}\")\n",
    "print(f\"\\nPhase 2 LightGBM CV: {phase2_val_auc_lgb:.4f}\")\n",
    "print(f\"LightGBM Improvement: {np.mean(lgb_cv_scores_p3) - phase2_val_auc_lgb:+.4f}\")\n",
    "print(f\"XGBoost Improvement:  {np.mean(xgb_cv_scores_p3) - phase2_val_auc_lgb:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d825916f",
   "metadata": {},
   "source": [
    "### Save Processed Data + MLflow + Save Models + Submissions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "83ef503d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to ../../data/processed/phase3_previous_application/\n"
     ]
    }
   ],
   "source": [
    "output_dir_p3 = '../../data/processed/phase3_previous_application'\n",
    "os.makedirs(output_dir_p3, exist_ok=True)\n",
    "\n",
    "pd.concat([train_ids, X_train_selected_p3.reset_index(drop=True)], axis=1).to_csv(\n",
    "    f'{output_dir_p3}/X_train.csv', index=False\n",
    ")\n",
    "pd.DataFrame(y_train).to_csv(f'{output_dir_p3}/y_train.csv', index=False)\n",
    "\n",
    "pd.concat([val_ids, X_val_selected_p3.reset_index(drop=True)], axis=1).to_csv(\n",
    "    f'{output_dir_p3}/X_val.csv', index=False\n",
    ")\n",
    "pd.DataFrame(y_val).to_csv(f'{output_dir_p3}/y_val.csv', index=False)\n",
    "\n",
    "pd.concat([test_ids, X_test_selected_p3.reset_index(drop=True)], axis=1).to_csv(\n",
    "    f'{output_dir_p3}/X_test.csv', index=False\n",
    ")\n",
    "\n",
    "feature_metadata_p3 = {\n",
    "    'phase': 'phase3_previous_application',\n",
    "    'base_phase': 'phase2_bureau_balance',\n",
    "    'n_phase2_features': len(phase2_selected_features),\n",
    "    'n_prev_features_created': prev_agg.shape[1] - 1,\n",
    "    'n_prev_features_after_level1': prev_features.shape[1],\n",
    "    'n_features_final': len(selected_features_p3),\n",
    "    'feature_list': selected_features_p3,\n",
    "    'phase2_features': [f for f in selected_features_p3 if f in phase2_selected_features],\n",
    "    'prev_features_new': prev_new_features,\n",
    "    'dropped_missing': prev_dropped_missing,\n",
    "    'dropped_variance': prev_dropped_variance,\n",
    "    'dropped_corr': prev_dropped_corr,\n",
    "    'importance_threshold': importance_threshold_p3,\n",
    "    'quick_eval': {\n",
    "        'lgb_val_auc': float(val_auc_lgb_p3),\n",
    "        'lgb_improvement': float(val_auc_lgb_p3 - phase2_val_auc_lgb),\n",
    "        'xgb_val_auc': float(val_auc_xgb_p3),\n",
    "        'xgb_improvement': float(val_auc_xgb_p3 - phase2_val_auc_lgb)\n",
    "    },\n",
    "    'cv_eval': {\n",
    "        'lgb_cv_mean': float(np.mean(lgb_cv_scores_p3)),\n",
    "        'lgb_cv_std': float(np.std(lgb_cv_scores_p3)),\n",
    "        'lgb_improvement_cv': float(np.mean(lgb_cv_scores_p3) - phase2_val_auc_lgb),\n",
    "        'xgb_cv_mean': float(np.mean(xgb_cv_scores_p3)),\n",
    "        'xgb_cv_std': float(np.std(xgb_cv_scores_p3)),\n",
    "        'xgb_improvement_cv': float(np.mean(xgb_cv_scores_p3) - phase2_val_auc_lgb)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f'{output_dir_p3}/feature_metadata.json', 'w') as f:\n",
    "    json.dump(feature_metadata_p3, f, indent=2)\n",
    "\n",
    "print(f\"Saved processed data to {output_dir_p3}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a6e59508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 22:35:34 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/12 22:35:38 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf2ecc4bf754384af8480bb496a61ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 22:35:38 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged LightGBM to MLflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 22:35:42 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019e8f4564ac47c09ade9640e8a76bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged XGBoost to MLflow\n"
     ]
    }
   ],
   "source": [
    "mlflow_tracking_uri = os.path.join(os.getcwd(), 'mlruns')\n",
    "mlflow.set_tracking_uri(f\"file:///{mlflow_tracking_uri}\")\n",
    "mlflow.set_experiment(\"feature_engineering\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"phase3_previous_application_lightgbm\"):\n",
    "    mlflow.log_param(\"phase\", \"previous_application\")\n",
    "    mlflow.log_param(\"base_phase\", \"phase2_bureau_balance\")\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM\")\n",
    "    mlflow.log_param(\"n_estimators\", 500)\n",
    "    mlflow.log_param(\"learning_rate\", 0.05)\n",
    "    mlflow.log_param(\"max_depth\", 7)\n",
    "    mlflow.log_param(\"n_phase2_features\", len(phase2_selected_features))\n",
    "    mlflow.log_param(\"n_prev_features_new\", len(prev_new_features))\n",
    "    mlflow.log_param(\"n_features_final\", len(selected_features_p3))\n",
    "    mlflow.log_param(\"importance_threshold\", importance_threshold_p3)\n",
    "    \n",
    "    mlflow.log_metric(\"quick_train_auc\", train_auc_lgb_p3)\n",
    "    mlflow.log_metric(\"quick_val_auc\", val_auc_lgb_p3)\n",
    "    mlflow.log_metric(\"cv_mean_auc\", np.mean(lgb_cv_scores_p3))\n",
    "    mlflow.log_metric(\"cv_std_auc\", np.std(lgb_cv_scores_p3))\n",
    "    mlflow.log_metric(\"phase2_val_auc\", phase2_val_auc_lgb)\n",
    "    mlflow.log_metric(\"improvement_quick\", val_auc_lgb_p3 - phase2_val_auc_lgb)\n",
    "    mlflow.log_metric(\"improvement_cv\", np.mean(lgb_cv_scores_p3) - phase2_val_auc_lgb)\n",
    "    \n",
    "    X_sample = X_train_selected_p3.iloc[:5].fillna(0)\n",
    "    y_sample = y_train.iloc[:5]\n",
    "    signature = mlflow.models.infer_signature(X_sample, y_sample)\n",
    "    \n",
    "    mlflow.sklearn.log_model(lgb_final_p3, \"model\", signature=signature, input_example=X_sample)\n",
    "    \n",
    "    lgb_importances_final_p3 = get_feature_importances(lgb_final_p3, selected_features_p3)\n",
    "    lgb_importances_final_p3.to_csv('feature_importance_lgb_p3.csv', index=False)\n",
    "    mlflow.log_artifact('feature_importance_lgb_p3.csv')\n",
    "    os.remove('feature_importance_lgb_p3.csv')\n",
    "    \n",
    "    with open('selected_features_p3.json', 'w') as f:\n",
    "        json.dump({'features': selected_features_p3}, f, indent=2)\n",
    "    mlflow.log_artifact('selected_features_p3.json')\n",
    "    os.remove('selected_features_p3.json')\n",
    "    \n",
    "    with open('dropped_features_p3.json', 'w') as f:\n",
    "        json.dump({\n",
    "            'dropped_missing': prev_dropped_missing,\n",
    "            'dropped_variance': prev_dropped_variance,\n",
    "            'dropped_correlation': prev_dropped_corr\n",
    "        }, f, indent=2)\n",
    "    mlflow.log_artifact('dropped_features_p3.json')\n",
    "    os.remove('dropped_features_p3.json')\n",
    "\n",
    "print(\"Logged LightGBM to MLflow\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"phase3_previous_application_xgboost\"):\n",
    "    mlflow.log_param(\"phase\", \"previous_application\")\n",
    "    mlflow.log_param(\"base_phase\", \"phase2_bureau_balance\")\n",
    "    mlflow.log_param(\"model_type\", \"XGBoost\")\n",
    "    mlflow.log_param(\"n_estimators\", 500)\n",
    "    mlflow.log_param(\"learning_rate\", 0.05)\n",
    "    mlflow.log_param(\"max_depth\", 7)\n",
    "    mlflow.log_param(\"n_phase2_features\", len(phase2_selected_features))\n",
    "    mlflow.log_param(\"n_prev_features_new\", len(prev_new_features))\n",
    "    mlflow.log_param(\"n_features_final\", len(selected_features_p3))\n",
    "    mlflow.log_param(\"importance_threshold\", importance_threshold_p3)\n",
    "    \n",
    "    mlflow.log_metric(\"quick_train_auc\", train_auc_xgb_p3)\n",
    "    mlflow.log_metric(\"quick_val_auc\", val_auc_xgb_p3)\n",
    "    mlflow.log_metric(\"cv_mean_auc\", np.mean(xgb_cv_scores_p3))\n",
    "    mlflow.log_metric(\"cv_std_auc\", np.std(xgb_cv_scores_p3))\n",
    "    mlflow.log_metric(\"phase2_val_auc\", phase2_val_auc_lgb)\n",
    "    mlflow.log_metric(\"improvement_quick\", val_auc_xgb_p3 - phase2_val_auc_lgb)\n",
    "    mlflow.log_metric(\"improvement_cv\", np.mean(xgb_cv_scores_p3) - phase2_val_auc_lgb)\n",
    "    \n",
    "    X_sample = X_train_selected_p3.iloc[:5].fillna(0)\n",
    "    y_sample = y_train.iloc[:5]\n",
    "    signature = mlflow.models.infer_signature(X_sample, y_sample)\n",
    "    \n",
    "    mlflow.sklearn.log_model(xgb_final_p3, \"model\", signature=signature, input_example=X_sample)\n",
    "    \n",
    "    xgb_importances_final_p3 = get_feature_importances(xgb_final_p3, selected_features_p3)\n",
    "    xgb_importances_final_p3.to_csv('feature_importance_xgb_p3.csv', index=False)\n",
    "    mlflow.log_artifact('feature_importance_xgb_p3.csv')\n",
    "    os.remove('feature_importance_xgb_p3.csv')\n",
    "    \n",
    "    with open('selected_features_p3.json', 'w') as f:\n",
    "        json.dump({'features': selected_features_p3}, f, indent=2)\n",
    "    mlflow.log_artifact('selected_features_p3.json')\n",
    "    os.remove('selected_features_p3.json')\n",
    "    \n",
    "    with open('dropped_features_p3.json', 'w') as f:\n",
    "        json.dump({\n",
    "            'dropped_missing': prev_dropped_missing,\n",
    "            'dropped_variance': prev_dropped_variance,\n",
    "            'dropped_correlation': prev_dropped_corr\n",
    "        }, f, indent=2)\n",
    "    mlflow.log_artifact('dropped_features_p3.json')\n",
    "    os.remove('dropped_features_p3.json')\n",
    "\n",
    "print(\"Logged XGBoost to MLflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f9c1e0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../../models/phase3_previous_application/lightgbm_v1.pkl\n",
      "Model saved to ../../models/phase3_previous_application/xgboost_v1.pkl\n"
     ]
    }
   ],
   "source": [
    "output_model_dir_p3 = '../../models/phase3_previous_application'\n",
    "os.makedirs(output_model_dir_p3, exist_ok=True)\n",
    "\n",
    "model_artifacts_lgb_p3 = {\n",
    "    'model': lgb_final_p3,\n",
    "    'selected_features': selected_features_p3,\n",
    "    'categorical_features': CATEGORICAL_FEATURES,\n",
    "    'cat_mappings': cat_mappings,\n",
    "    'quick_val_auc': val_auc_lgb_p3,\n",
    "    'cv_mean_auc': np.mean(lgb_cv_scores_p3),\n",
    "    'cv_std_auc': np.std(lgb_cv_scores_p3),\n",
    "    'phase2_val_auc': phase2_val_auc_lgb,\n",
    "    'improvement': val_auc_lgb_p3 - phase2_val_auc_lgb\n",
    "}\n",
    "\n",
    "joblib.dump(model_artifacts_lgb_p3, f'{output_model_dir_p3}/lightgbm_v1.pkl')\n",
    "print(f\"Model saved to {output_model_dir_p3}/lightgbm_v1.pkl\")\n",
    "\n",
    "model_artifacts_xgb_p3 = {\n",
    "    'model': xgb_final_p3,\n",
    "    'selected_features': selected_features_p3,\n",
    "    'categorical_features': CATEGORICAL_FEATURES,\n",
    "    'cat_mappings': cat_mappings,\n",
    "    'quick_val_auc': val_auc_xgb_p3,\n",
    "    'cv_mean_auc': np.mean(xgb_cv_scores_p3),\n",
    "    'cv_std_auc': np.std(xgb_cv_scores_p3),\n",
    "    'phase2_val_auc': phase2_val_auc_lgb,\n",
    "    'improvement': val_auc_xgb_p3 - phase2_val_auc_lgb\n",
    "}\n",
    "\n",
    "joblib.dump(model_artifacts_xgb_p3, f'{output_model_dir_p3}/xgboost_v1.pkl')\n",
    "print(f\"Model saved to {output_model_dir_p3}/xgboost_v1.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "aa4cf8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission files created:\n",
      "  phase3_previous_application_lightgbm_v1.csv\n",
      "  phase3_previous_application_xgboost_v1.csv\n",
      "\n",
      "LightGBM predictions - Min: 0.0064, Max: 0.9524, Mean: 0.3682\n",
      "XGBoost predictions  - Min: 0.0016, Max: 0.9737, Mean: 0.3232\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('../../data/raw/sample_submission.csv')\n",
    "\n",
    "lgb_preds_p3 = lgb_final_p3.predict_proba(X_test_selected_p3)[:, 1]\n",
    "xgb_preds_p3 = xgb_final_p3.predict_proba(X_test_selected_p3)[:, 1]\n",
    "\n",
    "submission_lgb_p3 = sample_submission.copy()\n",
    "submission_lgb_p3['TARGET'] = lgb_preds_p3\n",
    "\n",
    "submission_xgb_p3 = sample_submission.copy()\n",
    "submission_xgb_p3['TARGET'] = xgb_preds_p3\n",
    "\n",
    "os.makedirs('../../data/submissions', exist_ok=True)\n",
    "\n",
    "submission_lgb_p3.to_csv('../../data/submissions/phase3_previous_application_lightgbm_v1.csv', index=False)\n",
    "submission_xgb_p3.to_csv('../../data/submissions/phase3_previous_application_xgboost_v1.csv', index=False)\n",
    "\n",
    "print(\"Submission files created:\")\n",
    "print(\"  phase3_previous_application_lightgbm_v1.csv\")\n",
    "print(\"  phase3_previous_application_xgboost_v1.csv\")\n",
    "print(f\"\\nLightGBM predictions - Min: {lgb_preds_p3.min():.4f}, Max: {lgb_preds_p3.max():.4f}, Mean: {lgb_preds_p3.mean():.4f}\")\n",
    "print(f\"XGBoost predictions  - Min: {xgb_preds_p3.min():.4f}, Max: {xgb_preds_p3.max():.4f}, Mean: {xgb_preds_p3.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889a010b",
   "metadata": {},
   "source": [
    "### Phase 3 Summary\n",
    "\n",
    "**Strategy:** Previous application history with approval patterns and amount differences - highest impact phase.\n",
    "\n",
    "**Features Created:** 40 previous_application features (AMT_ANNUITY, AMT_GOODS_PRICE, CNT_PAYMENT, DAYS_DECISION, NAME_CONTRACT_STATUS/TYPE, approval_rate, app_credit_diff). Level 1 filtering: 1 variance + 7 correlation drops → 32 features. Level 2 selection: 15 new features. Final: 55 features total.\n",
    "\n",
    "**Results:** LightGBM Val 0.7720, CV 0.7710 (+0.0161 from Phase 2 - largest gain). XGBoost Val 0.7652, CV 0.7641. Kaggle: LightGBM Private 0.76267/Public 0.75670, XGBoost Private 0.75218/Public 0.74200.\n",
    "\n",
    "**Top Contributors:** prev_approval_rate, prev_app_credit_diff, prev_DAYS_DECISION patterns, prev_AMT_ANNUITY aggregations. Application history highly predictive.\n",
    "\n",
    "**Insight:** Strongest phase. Approval patterns and application timing critical for credit risk.\n",
    "\n",
    "**Saved:** Processed data and models to phase3_previous_application/, tracked in MLflow, submissions generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56870772",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 4: POS & Credit Card Features\n",
    "\n",
    "**Base:** Phase 3 selected features (55)\n",
    "\n",
    "Add payment behavior patterns from POS and Credit Card"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19ab8fc",
   "metadata": {},
   "source": [
    "### Load Phase 3 Base Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "0f8880ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 3 Base Features: 55\n",
      "Phase 3 LightGBM CV AUC: 0.7710\n",
      "train_df shape: (246008, 37), val_df shape: (61503, 37), test_df shape: (48744, 121)\n"
     ]
    }
   ],
   "source": [
    "with open('../../data/processed/phase3_previous_application/feature_metadata.json', 'r') as f:\n",
    "    phase3_metadata = json.load(f)\n",
    "\n",
    "phase3_selected_features = phase3_metadata['feature_list']\n",
    "phase3_val_auc_lgb = phase3_metadata['cv_eval']['lgb_cv_mean']\n",
    "\n",
    "train_ids = df.loc[X_train.index, 'SK_ID_CURR'].reset_index(drop=True)\n",
    "val_ids = df.loc[X_val.index, 'SK_ID_CURR'].reset_index(drop=True)\n",
    "test_ids = test_df['SK_ID_CURR'].reset_index(drop=True)\n",
    "\n",
    "train_df = pd.concat([train_ids, X_train.reset_index(drop=True)], axis=1)\n",
    "val_df = pd.concat([val_ids, X_val.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(f\"Phase 3 Base Features: {len(phase3_selected_features)}\")\n",
    "print(f\"Phase 3 LightGBM CV AUC: {phase3_val_auc_lgb:.4f}\")\n",
    "print(f\"train_df shape: {train_df.shape}, val_df shape: {val_df.shape}, test_df shape: {test_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711e29e0",
   "metadata": {},
   "source": [
    "### POS & Credit Card Aggregations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "f007d44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Cash Balance shape: (10001358, 8)\n",
      "Unique SK_ID_PREV (POS): 936325\n",
      "Credit Card Balance shape: (3840312, 23)\n",
      "Unique SK_ID_PREV (CC): 104307\n"
     ]
    }
   ],
   "source": [
    "pos = pd.read_csv('../../data/raw/POS_CASH_balance.csv')\n",
    "cc = pd.read_csv('../../data/raw/credit_card_balance.csv')\n",
    "\n",
    "print(f\"POS Cash Balance shape: {pos.shape}\")\n",
    "print(f\"Unique SK_ID_PREV (POS): {pos['SK_ID_PREV'].nunique()}\")\n",
    "print(f\"Credit Card Balance shape: {cc.shape}\")\n",
    "print(f\"Unique SK_ID_PREV (CC): {cc['SK_ID_PREV'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "8bf6dd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS features created: 26\n"
     ]
    }
   ],
   "source": [
    "pos_agg = pos.groupby('SK_ID_PREV').agg({\n",
    "    'MONTHS_BALANCE': ['min', 'max', 'size'],\n",
    "    'CNT_INSTALMENT': ['min', 'max', 'mean', 'sum'],\n",
    "    'CNT_INSTALMENT_FUTURE': ['min', 'max', 'mean', 'sum'],\n",
    "    'SK_DPD': ['max', 'mean', 'sum'],\n",
    "    'SK_DPD_DEF': ['max', 'mean', 'sum']\n",
    "}).reset_index()\n",
    "\n",
    "pos_agg.columns = ['SK_ID_PREV'] + [f'pos_{col[0]}_{col[1]}' for col in pos_agg.columns[1:]]\n",
    "\n",
    "pos_status = aggregate_categorical_ohe(pos, 'SK_ID_PREV', 'NAME_CONTRACT_STATUS', 'pos_status')\n",
    "pos_agg = pos_agg.merge(pos_status, on='SK_ID_PREV', how='left')\n",
    "\n",
    "prev_to_curr = prev[['SK_ID_PREV', 'SK_ID_CURR']].drop_duplicates()\n",
    "pos_by_curr = pos_agg.merge(prev_to_curr, on='SK_ID_PREV', how='left')\n",
    "\n",
    "pos_features = pos_by_curr.drop(columns=['SK_ID_PREV']).groupby('SK_ID_CURR').agg('mean').reset_index()\n",
    "\n",
    "print(f\"POS features created: {pos_features.shape[1] - 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "a33675db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit Card features created: 28\n"
     ]
    }
   ],
   "source": [
    "cc_agg = cc.groupby('SK_ID_PREV').agg({\n",
    "    'MONTHS_BALANCE': ['min', 'max', 'size'],\n",
    "    'AMT_BALANCE': ['min', 'max', 'mean', 'std'],\n",
    "    'AMT_CREDIT_LIMIT_ACTUAL': ['min', 'max', 'mean'],\n",
    "    'AMT_DRAWINGS_ATM_CURRENT': ['max', 'mean', 'sum'],\n",
    "    'AMT_DRAWINGS_CURRENT': ['max', 'mean', 'sum'],\n",
    "    'AMT_PAYMENT_CURRENT': ['min', 'max', 'mean', 'sum'],\n",
    "    'SK_DPD': ['max', 'mean', 'sum'],\n",
    "    'SK_DPD_DEF': ['max', 'mean', 'sum']\n",
    "}).reset_index()\n",
    "\n",
    "cc_agg.columns = ['SK_ID_PREV'] + [f'cc_{col[0]}_{col[1]}' for col in cc_agg.columns[1:]]\n",
    "\n",
    "cc_agg['cc_balance_limit_ratio'] = cc_agg['cc_AMT_BALANCE_mean'] / (cc_agg['cc_AMT_CREDIT_LIMIT_ACTUAL_mean'] + 1)\n",
    "cc_agg['cc_payment_balance_ratio'] = cc_agg['cc_AMT_PAYMENT_CURRENT_mean'] / (cc_agg['cc_AMT_BALANCE_mean'] + 1)\n",
    "\n",
    "cc_by_curr = cc_agg.merge(prev_to_curr, on='SK_ID_PREV', how='left')\n",
    "cc_features = cc_by_curr.drop(columns=['SK_ID_PREV']).groupby('SK_ID_CURR').agg('mean').reset_index()\n",
    "\n",
    "print(f\"Credit Card features created: {cc_features.shape[1] - 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "292e8092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total POS + CC features: 54\n"
     ]
    }
   ],
   "source": [
    "pos_cc_features = pos_features.merge(cc_features, on='SK_ID_CURR', how='outer')\n",
    "\n",
    "print(f\"Total POS + CC features: {pos_cc_features.shape[1] - 1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0543d55",
   "metadata": {},
   "source": [
    "### Level 1 Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "e44a900b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS+CC features after Level 1 filtering: 33\n",
      "  Dropped by missing: 6\n",
      "  Dropped by low variance: 5\n",
      "  Dropped by correlation: 10\n"
     ]
    }
   ],
   "source": [
    "pos_cc_cols = [c for c in pos_cc_features.columns if c != 'SK_ID_CURR']\n",
    "\n",
    "pos_cc_filtered = pos_cc_features[['SK_ID_CURR'] + pos_cc_cols].copy()\n",
    "pos_cc_filtered, missing_dropped = filter_by_missing(pos_cc_filtered, threshold=0.80)\n",
    "pos_cc_filtered, var_dropped = remove_low_variance(pos_cc_filtered, threshold=0.01)\n",
    "pos_cc_filtered, corr_dropped = remove_correlated(pos_cc_filtered, threshold=0.95)\n",
    "\n",
    "print(f\"POS+CC features after Level 1 filtering: {len(pos_cc_filtered.columns) - 1}\")\n",
    "print(f\"  Dropped by missing: {len(missing_dropped)}\")\n",
    "print(f\"  Dropped by low variance: {len(var_dropped)}\")\n",
    "print(f\"  Dropped by correlation: {len(corr_dropped)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0443937",
   "metadata": {},
   "source": [
    "### Load Phase 3 Processed Data & Merge with POS/CC Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "9cdb7c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (246008, 88)\n",
      "X_val shape: (61503, 88)\n",
      "X_test shape: (48744, 88)\n"
     ]
    }
   ],
   "source": [
    "X_train_p3_df = pd.read_csv('../../data/processed/phase3_previous_application/X_train.csv')\n",
    "X_val_p3_df = pd.read_csv('../../data/processed/phase3_previous_application/X_val.csv')\n",
    "X_test_p3_df = pd.read_csv('../../data/processed/phase3_previous_application/X_test.csv')\n",
    "\n",
    "train_df_p4 = X_train_p3_df.merge(pos_cc_filtered, on='SK_ID_CURR', how='left')\n",
    "val_df_p4 = X_val_p3_df.merge(pos_cc_filtered, on='SK_ID_CURR', how='left')\n",
    "test_df_p4 = X_test_p3_df.merge(pos_cc_filtered, on='SK_ID_CURR', how='left')\n",
    "\n",
    "X_train_pos_cc = train_df_p4.drop(columns=['SK_ID_CURR'])\n",
    "X_val_pos_cc = val_df_p4.drop(columns=['SK_ID_CURR'])\n",
    "X_test_pos_cc = test_df_p4.drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "print(f\"X_train shape: {X_train_pos_cc.shape}\")\n",
    "print(f\"X_val shape: {X_val_pos_cc.shape}\")\n",
    "print(f\"X_test shape: {X_test_pos_cc.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7558c1e",
   "metadata": {},
   "source": [
    "### Preliminary Training (for Level 2 Filtering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "d3eb6c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preliminary LightGBM - Train AUC: 0.8566, Val AUC: 0.7730\n",
      "Preliminary XGBoost  - Train AUC: 0.9211, Val AUC: 0.7649\n",
      "CPU times: total: 6min 48s\n",
      "Wall time: 36.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_lgb_p4 = X_train_pos_cc.copy()\n",
    "X_val_lgb_p4 = X_val_pos_cc.copy()\n",
    "X_test_lgb_p4 = X_test_pos_cc.copy()\n",
    "\n",
    "for col in CATEGORICAL_FEATURES:\n",
    "    if col in X_train_lgb_p4.columns:\n",
    "        X_train_lgb_p4[col] = X_train_lgb_p4[col].map(cat_mappings[col]).fillna(-1).astype(int)\n",
    "        X_val_lgb_p4[col] = X_val_lgb_p4[col].map(cat_mappings[col]).fillna(-1).astype(int)\n",
    "        X_test_lgb_p4[col] = X_test_lgb_p4[col].map(cat_mappings[col]).fillna(-1).astype(int)\n",
    "\n",
    "lgb_pos_cc_prelim = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "xgb_pos_cc_prelim = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=(len(y_train) - y_train.sum()) / y_train.sum(),\n",
    "    eval_metric='logloss',\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "lgb_pos_cc_prelim.fit(X_train_lgb_p4, y_train, eval_set=[(X_val_lgb_p4, y_val)])\n",
    "xgb_pos_cc_prelim.fit(X_train_lgb_p4, y_train, eval_set=[(X_val_lgb_p4, y_val)], verbose=False)\n",
    "\n",
    "lgb_train_auc = roc_auc_score(y_train, lgb_pos_cc_prelim.predict_proba(X_train_lgb_p4)[:, 1])\n",
    "lgb_val_auc = roc_auc_score(y_val, lgb_pos_cc_prelim.predict_proba(X_val_lgb_p4)[:, 1])\n",
    "\n",
    "xgb_train_auc = roc_auc_score(y_train, xgb_pos_cc_prelim.predict_proba(X_train_lgb_p4)[:, 1])\n",
    "xgb_val_auc = roc_auc_score(y_val, xgb_pos_cc_prelim.predict_proba(X_val_lgb_p4)[:, 1])\n",
    "\n",
    "print(f\"Preliminary LightGBM - Train AUC: {lgb_train_auc:.4f}, Val AUC: {lgb_val_auc:.4f}\")\n",
    "print(f\"Preliminary XGBoost  - Train AUC: {xgb_train_auc:.4f}, Val AUC: {xgb_val_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c1332a",
   "metadata": {},
   "source": [
    "### Level 2 Filtering: Feature Importance Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "ee5929f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected by LightGBM (>20): 76\n",
      "Features selected by XGBoost (>20): 0\n",
      "Union of selected features: 76\n"
     ]
    }
   ],
   "source": [
    "lgb_importances_p4 = get_feature_importances(lgb_pos_cc_prelim, X_train_lgb_p4.columns)\n",
    "xgb_importances_p4 = get_feature_importances(xgb_pos_cc_prelim, X_train_lgb_p4.columns)\n",
    "\n",
    "importance_threshold = 20\n",
    "\n",
    "lgb_selected_p4 = select_by_importance_threshold(lgb_importances_p4, threshold=importance_threshold)\n",
    "xgb_selected_p4 = select_by_importance_threshold(xgb_importances_p4, threshold=importance_threshold)\n",
    "\n",
    "selected_features_p4 = list(set(lgb_selected_p4) | set(xgb_selected_p4))\n",
    "\n",
    "print(f\"Features selected by LightGBM (>{importance_threshold}): {len(lgb_selected_p4)}\")\n",
    "print(f\"Features selected by XGBoost (>{importance_threshold}): {len(xgb_selected_p4)}\")\n",
    "print(f\"Union of selected features: {len(selected_features_p4)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5bde30",
   "metadata": {},
   "source": [
    "### Final Model Training (with selected features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "76fa4f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final LightGBM - Train AUC: 0.8569, Val AUC: 0.7735\n",
      "Final XGBoost  - Train AUC: 0.9224, Val AUC: 0.7646\n",
      "CPU times: total: 6min 34s\n",
      "Wall time: 38.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train_selected_p4 = X_train_lgb_p4[selected_features_p4]\n",
    "X_val_selected_p4 = X_val_lgb_p4[selected_features_p4]\n",
    "X_test_selected_p4 = X_test_lgb_p4[selected_features_p4]\n",
    "\n",
    "lgb_final_p4 = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "xgb_final_p4 = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=(len(y_train) - y_train.sum()) / y_train.sum(),\n",
    "    eval_metric='logloss',\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "lgb_final_p4.fit(X_train_selected_p4, y_train, eval_set=[(X_val_selected_p4, y_val)])\n",
    "xgb_final_p4.fit(X_train_selected_p4, y_train, eval_set=[(X_val_selected_p4, y_val)], verbose=False)\n",
    "\n",
    "train_auc_lgb_p4 = roc_auc_score(y_train, lgb_final_p4.predict_proba(X_train_selected_p4)[:, 1])\n",
    "val_auc_lgb_p4 = roc_auc_score(y_val, lgb_final_p4.predict_proba(X_val_selected_p4)[:, 1])\n",
    "\n",
    "train_auc_xgb_p4 = roc_auc_score(y_train, xgb_final_p4.predict_proba(X_train_selected_p4)[:, 1])\n",
    "val_auc_xgb_p4 = roc_auc_score(y_val, xgb_final_p4.predict_proba(X_val_selected_p4)[:, 1])\n",
    "\n",
    "print(f\"Final LightGBM - Train AUC: {train_auc_lgb_p4:.4f}, Val AUC: {val_auc_lgb_p4:.4f}\")\n",
    "print(f\"Final XGBoost  - Train AUC: {train_auc_xgb_p4:.4f}, Val AUC: {val_auc_xgb_p4:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2268acea",
   "metadata": {},
   "source": [
    "### Quick Evaluation (80/20 Split - Phase 3 Comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "d6d7d5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "QUICK EVALUATION (80/20 Split)\n",
      "======================================================================\n",
      "   Model  Train AUC  Val AUC  Phase3 Val AUC  Improvement  Train-Val Gap\n",
      "LightGBM   0.856909 0.773550        0.770963     0.002586       0.083360\n",
      " XGBoost   0.922432 0.764555        0.770963    -0.006408       0.157877\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "comparison_p4 = pd.DataFrame({\n",
    "    'Model': ['LightGBM', 'XGBoost'],\n",
    "    'Train AUC': [train_auc_lgb_p4, train_auc_xgb_p4],\n",
    "    'Val AUC': [val_auc_lgb_p4, val_auc_xgb_p4],\n",
    "    'Phase3 Val AUC': [phase3_val_auc_lgb, phase3_val_auc_lgb],\n",
    "    'Improvement': [val_auc_lgb_p4 - phase3_val_auc_lgb, val_auc_xgb_p4 - phase3_val_auc_lgb],\n",
    "    'Train-Val Gap': [train_auc_lgb_p4 - val_auc_lgb_p4, train_auc_xgb_p4 - val_auc_xgb_p4]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"QUICK EVALUATION (80/20 Split)\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_p4.to_string(index=False))\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e1c028",
   "metadata": {},
   "source": [
    "### Cross-Validation (5-Fold StratifiedKFold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "7a617e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CROSS-VALIDATION (5-Fold)\n",
      "======================================================================\n",
      "LightGBM CV Scores: [0.7774428035763592, 0.768374578680938, 0.7686018554523939, 0.7709351241451896, 0.7728685441777108]\n",
      "LightGBM Mean: 0.7716 ± 0.0033\n",
      "Phase 3 LightGBM CV: 0.7710\n",
      "Improvement: +0.0007\n",
      "----------------------------------------------------------------------\n",
      "XGBoost CV Scores: [0.7694817915510809, 0.7616670158751924, 0.7612263879239861, 0.7623781276940422, 0.76232325537656]\n",
      "XGBoost Mean: 0.7634 ± 0.0031\n",
      "Phase 3 XGBoost: N/A (using LightGBM baseline)\n",
      "Improvement vs LightGBM: -0.0075\n",
      "======================================================================\n",
      "CPU times: total: 30min 22s\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_full = pd.concat([X_train, X_val], axis=0).reset_index(drop=True)\n",
    "y_full = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    "\n",
    "X_train_p3_full = pd.read_csv('../../data/processed/phase3_previous_application/X_train.csv')\n",
    "X_val_p3_full = pd.read_csv('../../data/processed/phase3_previous_application/X_val.csv')\n",
    "X_full_p3 = pd.concat([X_train_p3_full, X_val_p3_full], axis=0).reset_index(drop=True)\n",
    "\n",
    "X_full_p4 = X_full_p3.merge(pos_cc_filtered, on='SK_ID_CURR', how='left').drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "for col in CATEGORICAL_FEATURES:\n",
    "    if col in X_full_p4.columns:\n",
    "        X_full_p4[col] = X_full_p4[col].map(cat_mappings[col]).fillna(-1).astype(int)\n",
    "\n",
    "X_full_selected_p4 = X_full_p4[selected_features_p4]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "lgb_cv_scores_p4 = []\n",
    "xgb_cv_scores_p4 = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_full_selected_p4, y_full), 1):\n",
    "    X_tr, X_va = X_full_selected_p4.iloc[train_idx], X_full_selected_p4.iloc[val_idx]\n",
    "    y_tr, y_va = y_full.iloc[train_idx], y_full.iloc[val_idx]\n",
    "    \n",
    "    lgb_cv = LGBMClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=7,\n",
    "        num_leaves=31,\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    xgb_cv = XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=7,\n",
    "        random_state=42,\n",
    "        scale_pos_weight=(len(y_tr) - y_tr.sum()) / y_tr.sum(),\n",
    "        eval_metric='logloss',\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "    \n",
    "    lgb_cv.fit(X_tr, y_tr, eval_set=[(X_va, y_va)])\n",
    "    xgb_cv.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=False)\n",
    "    \n",
    "    lgb_va_auc = roc_auc_score(y_va, lgb_cv.predict_proba(X_va)[:, 1])\n",
    "    xgb_va_auc = roc_auc_score(y_va, xgb_cv.predict_proba(X_va)[:, 1])\n",
    "    \n",
    "    lgb_cv_scores_p4.append(lgb_va_auc)\n",
    "    xgb_cv_scores_p4.append(xgb_va_auc)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CROSS-VALIDATION (5-Fold)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"LightGBM CV Scores: {lgb_cv_scores_p4}\")\n",
    "print(f\"LightGBM Mean: {np.mean(lgb_cv_scores_p4):.4f} ± {np.std(lgb_cv_scores_p4):.4f}\")\n",
    "print(f\"Phase 3 LightGBM CV: {phase3_val_auc_lgb:.4f}\")\n",
    "print(f\"Improvement: {np.mean(lgb_cv_scores_p4) - phase3_val_auc_lgb:+.4f}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"XGBoost CV Scores: {xgb_cv_scores_p4}\")\n",
    "print(f\"XGBoost Mean: {np.mean(xgb_cv_scores_p4):.4f} ± {np.std(xgb_cv_scores_p4):.4f}\")\n",
    "print(f\"Phase 3 XGBoost: N/A (using LightGBM baseline)\")\n",
    "print(f\"Improvement vs LightGBM: {np.mean(xgb_cv_scores_p4) - phase3_val_auc_lgb:+.4f}\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0684e2e",
   "metadata": {},
   "source": [
    "### Save Processed Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "d0c9eaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ../../data/processed/phase4_pos_cc/\n"
     ]
    }
   ],
   "source": [
    "output_dir_p4 = '../../data/processed/phase4_pos_cc'\n",
    "os.makedirs(output_dir_p4, exist_ok=True)\n",
    "\n",
    "train_df_p4[['SK_ID_CURR'] + selected_features_p4].to_csv(f'{output_dir_p4}/X_train.csv', index=False)\n",
    "pd.DataFrame(y_train).to_csv(f'{output_dir_p4}/y_train.csv', index=False)\n",
    "\n",
    "val_df_p4[['SK_ID_CURR'] + selected_features_p4].to_csv(f'{output_dir_p4}/X_val.csv', index=False)\n",
    "pd.DataFrame(y_val).to_csv(f'{output_dir_p4}/y_val.csv', index=False)\n",
    "\n",
    "test_df_p4[['SK_ID_CURR'] + selected_features_p4].to_csv(f'{output_dir_p4}/X_test.csv', index=False)\n",
    "\n",
    "feature_metadata_p4 = {\n",
    "    'phase': 4,\n",
    "    'base_phase': 3,\n",
    "    'base_features': len(phase3_selected_features),\n",
    "    'pos_cc_features_created': len(pos_cc_cols),\n",
    "    'pos_cc_features_after_l1': len(pos_cc_filtered.columns) - 1,\n",
    "    'features_dropped_missing': missing_dropped,\n",
    "    'features_dropped_variance': var_dropped,\n",
    "    'features_dropped_correlation': corr_dropped,\n",
    "    'importance_threshold': importance_threshold,\n",
    "    'features_selected_lgb': len(lgb_selected_p4),\n",
    "    'features_selected_xgb': len(xgb_selected_p4),\n",
    "    'feature_list': selected_features_p4,\n",
    "    'quick_eval': {\n",
    "        'lgb_train_auc': train_auc_lgb_p4,\n",
    "        'lgb_val_auc': val_auc_lgb_p4,\n",
    "        'xgb_train_auc': train_auc_xgb_p4,\n",
    "        'xgb_val_auc': val_auc_xgb_p4,\n",
    "        'phase3_baseline': phase3_val_auc_lgb\n",
    "    },\n",
    "    'cv_eval': {\n",
    "        'lgb_cv_scores': lgb_cv_scores_p4,\n",
    "        'lgb_cv_mean': np.mean(lgb_cv_scores_p4),\n",
    "        'lgb_cv_std': np.std(lgb_cv_scores_p4),\n",
    "        'xgb_cv_scores': xgb_cv_scores_p4,\n",
    "        'xgb_cv_mean': np.mean(xgb_cv_scores_p4),\n",
    "        'xgb_cv_std': np.std(xgb_cv_scores_p4)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f'{output_dir_p4}/feature_metadata.json', 'w') as f:\n",
    "    json.dump(feature_metadata_p4, f, indent=2)\n",
    "\n",
    "print(f\"Processed data saved to {output_dir_p4}/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a26338",
   "metadata": {},
   "source": [
    "### MLflow Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "e493153e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/13 00:46:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/13 00:47:01 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4d90d92ea24199a3c940c92e72c61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/13 00:47:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged LightGBM to MLflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/13 00:47:06 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac1b91c05fa41268e10844466057ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged XGBoost to MLflow\n"
     ]
    }
   ],
   "source": [
    "mlflow_tracking_uri = os.path.join(os.getcwd(), 'mlruns')\n",
    "mlflow.set_tracking_uri(f\"file:///{mlflow_tracking_uri}\")\n",
    "mlflow.set_experiment(\"feature_engineering\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"phase4_pos_cc_lightgbm\"):\n",
    "    mlflow.log_param(\"phase\", \"pos_cc\")\n",
    "    mlflow.log_param(\"base_phase\", \"phase3_previous_application\")\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM\")\n",
    "    mlflow.log_param(\"n_estimators\", 500)\n",
    "    mlflow.log_param(\"learning_rate\", 0.05)\n",
    "    mlflow.log_param(\"max_depth\", 7)\n",
    "    mlflow.log_param(\"num_leaves\", 31)\n",
    "    mlflow.log_param(\"n_phase3_features\", len(phase3_selected_features))\n",
    "    mlflow.log_param(\"n_pos_cc_features_created\", len(pos_cc_cols))\n",
    "    mlflow.log_param(\"n_pos_cc_features_after_l1\", len(pos_cc_filtered.columns) - 1)\n",
    "    mlflow.log_param(\"n_features_final\", len(selected_features_p4))\n",
    "    mlflow.log_param(\"importance_threshold\", importance_threshold)\n",
    "    \n",
    "    mlflow.log_metric(\"quick_train_auc\", train_auc_lgb_p4)\n",
    "    mlflow.log_metric(\"quick_val_auc\", val_auc_lgb_p4)\n",
    "    mlflow.log_metric(\"cv_mean_auc\", np.mean(lgb_cv_scores_p4))\n",
    "    mlflow.log_metric(\"cv_std_auc\", np.std(lgb_cv_scores_p4))\n",
    "    mlflow.log_metric(\"phase3_val_auc\", phase3_val_auc_lgb)\n",
    "    mlflow.log_metric(\"improvement_quick\", val_auc_lgb_p4 - phase3_val_auc_lgb)\n",
    "    mlflow.log_metric(\"improvement_cv\", np.mean(lgb_cv_scores_p4) - phase3_val_auc_lgb)\n",
    "    \n",
    "    X_sample = X_train_selected_p4.iloc[:5].fillna(0)\n",
    "    y_sample = y_train.iloc[:5]\n",
    "    signature = infer_signature(X_sample, y_sample)\n",
    "    \n",
    "    mlflow.sklearn.log_model(lgb_final_p4, \"model\", signature=signature, input_example=X_sample)\n",
    "    \n",
    "    lgb_imp_df = get_feature_importances(lgb_final_p4, selected_features_p4)\n",
    "    lgb_imp_df.to_csv('feature_importance_lgb_p4.csv', index=False)\n",
    "    mlflow.log_artifact('feature_importance_lgb_p4.csv')\n",
    "    os.remove('feature_importance_lgb_p4.csv')\n",
    "    \n",
    "    with open('selected_features_p4.json', 'w') as f:\n",
    "        json.dump({'features': selected_features_p4}, f, indent=2)\n",
    "    mlflow.log_artifact('selected_features_p4.json')\n",
    "    os.remove('selected_features_p4.json')\n",
    "    \n",
    "    with open('dropped_features_p4.json', 'w') as f:\n",
    "        json.dump({\n",
    "            'dropped_missing': missing_dropped,\n",
    "            'dropped_variance': var_dropped,\n",
    "            'dropped_correlation': corr_dropped\n",
    "        }, f, indent=2)\n",
    "    mlflow.log_artifact('dropped_features_p4.json')\n",
    "    os.remove('dropped_features_p4.json')\n",
    "\n",
    "print(\"Logged LightGBM to MLflow\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"phase4_pos_cc_xgboost\"):\n",
    "    mlflow.log_param(\"phase\", \"pos_cc\")\n",
    "    mlflow.log_param(\"base_phase\", \"phase3_previous_application\")\n",
    "    mlflow.log_param(\"model_type\", \"XGBoost\")\n",
    "    mlflow.log_param(\"n_estimators\", 500)\n",
    "    mlflow.log_param(\"learning_rate\", 0.05)\n",
    "    mlflow.log_param(\"max_depth\", 7)\n",
    "    mlflow.log_param(\"n_phase3_features\", len(phase3_selected_features))\n",
    "    mlflow.log_param(\"n_pos_cc_features_created\", len(pos_cc_cols))\n",
    "    mlflow.log_param(\"n_pos_cc_features_after_l1\", len(pos_cc_filtered.columns) - 1)\n",
    "    mlflow.log_param(\"n_features_final\", len(selected_features_p4))\n",
    "    mlflow.log_param(\"importance_threshold\", importance_threshold)\n",
    "    \n",
    "    mlflow.log_metric(\"quick_train_auc\", train_auc_xgb_p4)\n",
    "    mlflow.log_metric(\"quick_val_auc\", val_auc_xgb_p4)\n",
    "    mlflow.log_metric(\"cv_mean_auc\", np.mean(xgb_cv_scores_p4))\n",
    "    mlflow.log_metric(\"cv_std_auc\", np.std(xgb_cv_scores_p4))\n",
    "    mlflow.log_metric(\"phase3_val_auc\", phase3_val_auc_lgb)\n",
    "    mlflow.log_metric(\"improvement_quick\", val_auc_xgb_p4 - phase3_val_auc_lgb)\n",
    "    mlflow.log_metric(\"improvement_cv\", np.mean(xgb_cv_scores_p4) - phase3_val_auc_lgb)\n",
    "    \n",
    "    X_sample = X_train_selected_p4.iloc[:5].fillna(0)\n",
    "    y_sample = y_train.iloc[:5]\n",
    "    signature = infer_signature(X_sample, y_sample)\n",
    "    \n",
    "    mlflow.sklearn.log_model(xgb_final_p4, \"model\", signature=signature, input_example=X_sample)\n",
    "    \n",
    "    xgb_imp_df = get_feature_importances(xgb_final_p4, selected_features_p4)\n",
    "    xgb_imp_df.to_csv('feature_importance_xgb_p4.csv', index=False)\n",
    "    mlflow.log_artifact('feature_importance_xgb_p4.csv')\n",
    "    os.remove('feature_importance_xgb_p4.csv')\n",
    "    \n",
    "    with open('selected_features_p4.json', 'w') as f:\n",
    "        json.dump({'features': selected_features_p4}, f, indent=2)\n",
    "    mlflow.log_artifact('selected_features_p4.json')\n",
    "    os.remove('selected_features_p4.json')\n",
    "    \n",
    "    with open('dropped_features_p4.json', 'w') as f:\n",
    "        json.dump({\n",
    "            'dropped_missing': missing_dropped,\n",
    "            'dropped_variance': var_dropped,\n",
    "            'dropped_correlation': corr_dropped\n",
    "        }, f, indent=2)\n",
    "    mlflow.log_artifact('dropped_features_p4.json')\n",
    "    os.remove('dropped_features_p4.json')\n",
    "\n",
    "print(\"Logged XGBoost to MLflow\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a861d00",
   "metadata": {},
   "source": [
    "### Save Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "651ba504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../../models/phase4_pos_cc/lightgbm_v1.pkl\n",
      "Model saved to ../../models/phase4_pos_cc/xgboost_v1.pkl\n"
     ]
    }
   ],
   "source": [
    "output_model_dir_p4 = '../../models/phase4_pos_cc'\n",
    "os.makedirs(output_model_dir_p4, exist_ok=True)\n",
    "\n",
    "model_artifacts_lgb_p4 = {\n",
    "    'model': lgb_final_p4,\n",
    "    'selected_features': selected_features_p4,\n",
    "    'categorical_features': CATEGORICAL_FEATURES,\n",
    "    'cat_mappings': cat_mappings,\n",
    "    'quick_val_auc': val_auc_lgb_p4,\n",
    "    'cv_mean_auc': np.mean(lgb_cv_scores_p4),\n",
    "    'cv_std_auc': np.std(lgb_cv_scores_p4),\n",
    "    'phase3_val_auc': phase3_val_auc_lgb,\n",
    "    'improvement': val_auc_lgb_p4 - phase3_val_auc_lgb\n",
    "}\n",
    "\n",
    "joblib.dump(model_artifacts_lgb_p4, f'{output_model_dir_p4}/lightgbm_v1.pkl')\n",
    "print(f\"Model saved to {output_model_dir_p4}/lightgbm_v1.pkl\")\n",
    "\n",
    "model_artifacts_xgb_p4 = {\n",
    "    'model': xgb_final_p4,\n",
    "    'selected_features': selected_features_p4,\n",
    "    'categorical_features': CATEGORICAL_FEATURES,\n",
    "    'cat_mappings': cat_mappings,\n",
    "    'quick_val_auc': val_auc_xgb_p4,\n",
    "    'cv_mean_auc': np.mean(xgb_cv_scores_p4),\n",
    "    'cv_std_auc': np.std(xgb_cv_scores_p4),\n",
    "    'phase3_val_auc': phase3_val_auc_lgb,\n",
    "    'improvement': val_auc_xgb_p4 - phase3_val_auc_lgb\n",
    "}\n",
    "\n",
    "joblib.dump(model_artifacts_xgb_p4, f'{output_model_dir_p4}/xgboost_v1.pkl')\n",
    "print(f\"Model saved to {output_model_dir_p4}/xgboost_v1.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e8000",
   "metadata": {},
   "source": [
    "### Generate Kaggle Submissions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "f83e0285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission files created:\n",
      "  phase4_pos_cc_lightgbm_v1.csv\n",
      "  phase4_pos_cc_xgboost_v1.csv\n",
      "\n",
      "LightGBM predictions - Min: 0.0052, Max: 0.9574, Mean: 0.3612\n",
      "XGBoost predictions  - Min: 0.0009, Max: 0.9638, Mean: 0.3177\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('../../data/raw/sample_submission.csv')\n",
    "\n",
    "lgb_preds_p4 = lgb_final_p4.predict_proba(X_test_selected_p4)[:, 1]\n",
    "xgb_preds_p4 = xgb_final_p4.predict_proba(X_test_selected_p4)[:, 1]\n",
    "\n",
    "submission_lgb_p4 = sample_submission.copy()\n",
    "submission_lgb_p4['TARGET'] = lgb_preds_p4\n",
    "\n",
    "submission_xgb_p4 = sample_submission.copy()\n",
    "submission_xgb_p4['TARGET'] = xgb_preds_p4\n",
    "\n",
    "os.makedirs('../../data/submissions', exist_ok=True)\n",
    "\n",
    "submission_lgb_p4.to_csv('../../data/submissions/phase4_pos_cc_lightgbm_v1.csv', index=False)\n",
    "submission_xgb_p4.to_csv('../../data/submissions/phase4_pos_cc_xgboost_v1.csv', index=False)\n",
    "\n",
    "print(\"Submission files created:\")\n",
    "print(\"  phase4_pos_cc_lightgbm_v1.csv\")\n",
    "print(\"  phase4_pos_cc_xgboost_v1.csv\")\n",
    "print(f\"\\nLightGBM predictions - Min: {lgb_preds_p4.min():.4f}, Max: {lgb_preds_p4.max():.4f}, Mean: {lgb_preds_p4.mean():.4f}\")\n",
    "print(f\"XGBoost predictions  - Min: {xgb_preds_p4.min():.4f}, Max: {xgb_preds_p4.max():.4f}, Mean: {xgb_preds_p4.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e201cac",
   "metadata": {},
   "source": [
    "### Phase 4 Summary\n",
    "\n",
    "**Strategy:** Payment behavior from POS Cash Balance and Credit Card - credit utilization and late payment patterns.\n",
    "\n",
    "**Features Created:** 54 POS/CC features (CNT_INSTALMENT, SK_DPD, AMT_BALANCE, AMT_CREDIT_LIMIT, AMT_DRAWINGS, AMT_PAYMENT, balance_limit_ratio, payment_balance_ratio). Level 1 filtering: 6 missing + 5 variance + 10 correlation drops → 33 features. Level 2 selection (LightGBM only): 21 new features. Final: 76 features total.\n",
    "\n",
    "**Results:** LightGBM Val 0.7735, CV 0.7716 (+0.0007 from Phase 3 - minimal gain). XGBoost Val 0.7646, CV 0.7634. Kaggle: LightGBM Private 0.76491/Public 0.75697, XGBoost Private 0.75626/Public 0.75002.\n",
    "\n",
    "**Top Contributors:** cc_balance_limit_ratio, pos_SK_DPD metrics, cc_AMT_PAYMENT aggregations, pos_CNT_INSTALMENT_FUTURE. Credit utilization ratios valuable.\n",
    "\n",
    "**Insight:** Moderate impact. Payment behavior adds incremental value. \n",
    "\n",
    "**Saved:** Processed data and models to phase4_pos_cc/, tracked in MLflow, submissions generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fbefbd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 5: Installments Payments Features\n",
    "\n",
    "**Base:** Phase 4 selected features\n",
    "\n",
    " Add payment discipline patterns from installment history\n",
    "\n",
    " Payment timing, amounts, and delay patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011717f1",
   "metadata": {},
   "source": [
    "### Load Phase 4 Base Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "12da950e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 4 Base Features: 76\n",
      "Phase 4 LightGBM CV AUC: 0.7716\n"
     ]
    }
   ],
   "source": [
    "with open('../../data/processed/phase4_pos_cc/feature_metadata.json', 'r') as f:\n",
    "    phase4_metadata = json.load(f)\n",
    "\n",
    "phase4_selected_features = phase4_metadata['feature_list']\n",
    "phase4_val_auc_lgb = phase4_metadata['cv_eval']['lgb_cv_mean']\n",
    "\n",
    "print(f\"Phase 4 Base Features: {len(phase4_selected_features)}\")\n",
    "print(f\"Phase 4 LightGBM CV AUC: {phase4_val_auc_lgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c341afa1",
   "metadata": {},
   "source": [
    "### Installments Payments Aggregations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "1933604a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installments Payments shape: (13605401, 8)\n",
      "Unique SK_ID_PREV: 997752\n"
     ]
    }
   ],
   "source": [
    "inst = pd.read_csv('../../data/raw/installments_payments.csv')\n",
    "\n",
    "print(f\"Installments Payments shape: {inst.shape}\")\n",
    "print(f\"Unique SK_ID_PREV: {inst['SK_ID_PREV'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "07e58d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installments features created: 30\n"
     ]
    }
   ],
   "source": [
    "inst['inst_payment_delay'] = inst['DAYS_ENTRY_PAYMENT'] - inst['DAYS_INSTALMENT']\n",
    "inst['inst_payment_diff'] = inst['AMT_PAYMENT'] - inst['AMT_INSTALMENT']\n",
    "inst['inst_payment_ratio'] = inst['AMT_PAYMENT'] / (inst['AMT_INSTALMENT'] + 1)\n",
    "\n",
    "inst_agg = inst.groupby('SK_ID_PREV').agg({\n",
    "    'NUM_INSTALMENT_VERSION': ['max', 'nunique'],\n",
    "    'NUM_INSTALMENT_NUMBER': ['max', 'mean'],\n",
    "    'DAYS_INSTALMENT': ['min', 'max', 'mean'],\n",
    "    'DAYS_ENTRY_PAYMENT': ['min', 'max', 'mean'],\n",
    "    'AMT_INSTALMENT': ['min', 'max', 'mean', 'sum'],\n",
    "    'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "    'inst_payment_delay': ['max', 'mean', 'sum'],\n",
    "    'inst_payment_diff': ['min', 'max', 'mean', 'sum'],\n",
    "    'inst_payment_ratio': ['min', 'max', 'mean']\n",
    "}).reset_index()\n",
    "\n",
    "inst_agg.columns = ['SK_ID_PREV'] + [f'inst_{col[0]}_{col[1]}' for col in inst_agg.columns[1:]]\n",
    "\n",
    "inst_agg['inst_late_payment_count'] = (inst.groupby('SK_ID_PREV')['inst_payment_delay'].apply(lambda x: (x > 0).sum())).values\n",
    "inst_agg['inst_late_payment_ratio'] = inst_agg['inst_late_payment_count'] / (inst_agg['inst_NUM_INSTALMENT_NUMBER_max'] + 1)\n",
    "\n",
    "prev_to_curr = prev[['SK_ID_PREV', 'SK_ID_CURR']].drop_duplicates()\n",
    "inst_by_curr = inst_agg.merge(prev_to_curr, on='SK_ID_PREV', how='left')\n",
    "inst_features = inst_by_curr.drop(columns=['SK_ID_PREV']).groupby('SK_ID_CURR').agg('mean').reset_index()\n",
    "\n",
    "print(f\"Installments features created: {inst_features.shape[1] - 1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2b216a",
   "metadata": {},
   "source": [
    "### Level 1 Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "18f53d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installments features after Level 1 filtering: 19\n",
      "  Dropped by missing: 0\n",
      "  Dropped by low variance: 0\n",
      "  Dropped by correlation: 11\n"
     ]
    }
   ],
   "source": [
    "inst_cols = [c for c in inst_features.columns if c != 'SK_ID_CURR']\n",
    "\n",
    "inst_filtered = inst_features[['SK_ID_CURR'] + inst_cols].copy()\n",
    "inst_filtered, inst_missing_dropped = filter_by_missing(inst_filtered, threshold=0.80)\n",
    "inst_filtered, inst_var_dropped = remove_low_variance(inst_filtered, threshold=0.01)\n",
    "inst_filtered, inst_corr_dropped = remove_correlated(inst_filtered, threshold=0.95)\n",
    "\n",
    "print(f\"Installments features after Level 1 filtering: {len(inst_filtered.columns) - 1}\")\n",
    "print(f\"  Dropped by missing: {len(inst_missing_dropped)}\")\n",
    "print(f\"  Dropped by low variance: {len(inst_var_dropped)}\")\n",
    "print(f\"  Dropped by correlation: {len(inst_corr_dropped)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8ff584",
   "metadata": {},
   "source": [
    "### Load Phase 4 Processed Data & Merge with Installments Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "d7b894a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (246008, 95)\n",
      "X_val shape: (61503, 95)\n",
      "X_test shape: (48744, 95)\n"
     ]
    }
   ],
   "source": [
    "X_train_p4_df = pd.read_csv('../../data/processed/phase4_pos_cc/X_train.csv')\n",
    "X_val_p4_df = pd.read_csv('../../data/processed/phase4_pos_cc/X_val.csv')\n",
    "X_test_p4_df = pd.read_csv('../../data/processed/phase4_pos_cc/X_test.csv')\n",
    "\n",
    "train_df_p5 = X_train_p4_df.merge(inst_filtered, on='SK_ID_CURR', how='left')\n",
    "val_df_p5 = X_val_p4_df.merge(inst_filtered, on='SK_ID_CURR', how='left')\n",
    "test_df_p5 = X_test_p4_df.merge(inst_filtered, on='SK_ID_CURR', how='left')\n",
    "\n",
    "X_train_inst = train_df_p5.drop(columns=['SK_ID_CURR'])\n",
    "X_val_inst = val_df_p5.drop(columns=['SK_ID_CURR'])\n",
    "X_test_inst = test_df_p5.drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "print(f\"X_train shape: {X_train_inst.shape}\")\n",
    "print(f\"X_val shape: {X_val_inst.shape}\")\n",
    "print(f\"X_test shape: {X_test_inst.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5179b212",
   "metadata": {},
   "source": [
    "### Preliminary Training (for Level 2 Filtering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "69f252c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preliminary LightGBM - Train AUC: 0.8624, Val AUC: 0.7765\n",
      "Preliminary XGBoost  - Train AUC: 0.9296, Val AUC: 0.7677\n",
      "CPU times: total: 7min 53s\n",
      "Wall time: 43.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_lgb_p5 = X_train_inst.copy()\n",
    "X_val_lgb_p5 = X_val_inst.copy()\n",
    "X_test_lgb_p5 = X_test_inst.copy()\n",
    "\n",
    "for col in CATEGORICAL_FEATURES:\n",
    "    if col in X_train_lgb_p5.columns:\n",
    "        X_train_lgb_p5[col] = X_train_lgb_p5[col].map(cat_mappings[col]).fillna(-1).astype(int)\n",
    "        X_val_lgb_p5[col] = X_val_lgb_p5[col].map(cat_mappings[col]).fillna(-1).astype(int)\n",
    "        X_test_lgb_p5[col] = X_test_lgb_p5[col].map(cat_mappings[col]).fillna(-1).astype(int)\n",
    "\n",
    "lgb_inst_prelim = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "xgb_inst_prelim = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=(len(y_train) - y_train.sum()) / y_train.sum(),\n",
    "    eval_metric='logloss',\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "lgb_inst_prelim.fit(X_train_lgb_p5, y_train, eval_set=[(X_val_lgb_p5, y_val)])\n",
    "xgb_inst_prelim.fit(X_train_lgb_p5, y_train, eval_set=[(X_val_lgb_p5, y_val)], verbose=False)\n",
    "\n",
    "lgb_train_auc = roc_auc_score(y_train, lgb_inst_prelim.predict_proba(X_train_lgb_p5)[:, 1])\n",
    "lgb_val_auc = roc_auc_score(y_val, lgb_inst_prelim.predict_proba(X_val_lgb_p5)[:, 1])\n",
    "\n",
    "xgb_train_auc = roc_auc_score(y_train, xgb_inst_prelim.predict_proba(X_train_lgb_p5)[:, 1])\n",
    "xgb_val_auc = roc_auc_score(y_val, xgb_inst_prelim.predict_proba(X_val_lgb_p5)[:, 1])\n",
    "\n",
    "print(f\"Preliminary LightGBM - Train AUC: {lgb_train_auc:.4f}, Val AUC: {lgb_val_auc:.4f}\")\n",
    "print(f\"Preliminary XGBoost  - Train AUC: {xgb_train_auc:.4f}, Val AUC: {xgb_val_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef342f3c",
   "metadata": {},
   "source": [
    "### Level 2 Filtering: Feature Importance Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "1ac671f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected by LightGBM (>20): 95\n",
      "Features selected by XGBoost (>20): 0\n",
      "Union of selected features: 95\n"
     ]
    }
   ],
   "source": [
    "lgb_importances_p5 = get_feature_importances(lgb_inst_prelim, X_train_lgb_p5.columns)\n",
    "xgb_importances_p5 = get_feature_importances(xgb_inst_prelim, X_train_lgb_p5.columns)\n",
    "\n",
    "importance_threshold = 20\n",
    "\n",
    "lgb_selected_p5 = select_by_importance_threshold(lgb_importances_p5, threshold=importance_threshold)\n",
    "xgb_selected_p5 = select_by_importance_threshold(xgb_importances_p5, threshold=importance_threshold)\n",
    "\n",
    "selected_features_p5 = list(set(lgb_selected_p5) | set(xgb_selected_p5))\n",
    "\n",
    "print(f\"Features selected by LightGBM (>{importance_threshold}): {len(lgb_selected_p5)}\")\n",
    "print(f\"Features selected by XGBoost (>{importance_threshold}): {len(xgb_selected_p5)}\")\n",
    "print(f\"Union of selected features: {len(selected_features_p5)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fb2dbd",
   "metadata": {},
   "source": [
    "### Final Model Training (with selected features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "95bd667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final LightGBM - Train AUC: 0.8624, Val AUC: 0.7765\n",
      "Final XGBoost  - Train AUC: 0.9296, Val AUC: 0.7677\n",
      "CPU times: total: 8min 2s\n",
      "Wall time: 44.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_selected_p5 = X_train_lgb_p5[selected_features_p5]\n",
    "X_val_selected_p5 = X_val_lgb_p5[selected_features_p5]\n",
    "X_test_selected_p5 = X_test_lgb_p5[selected_features_p5]\n",
    "\n",
    "lgb_final_p5 = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "xgb_final_p5 = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=(len(y_train) - y_train.sum()) / y_train.sum(),\n",
    "    eval_metric='logloss',\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "lgb_final_p5.fit(X_train_selected_p5, y_train, eval_set=[(X_val_selected_p5, y_val)])\n",
    "xgb_final_p5.fit(X_train_selected_p5, y_train, eval_set=[(X_val_selected_p5, y_val)], verbose=False)\n",
    "\n",
    "train_auc_lgb_p5 = roc_auc_score(y_train, lgb_final_p5.predict_proba(X_train_selected_p5)[:, 1])\n",
    "val_auc_lgb_p5 = roc_auc_score(y_val, lgb_final_p5.predict_proba(X_val_selected_p5)[:, 1])\n",
    "\n",
    "train_auc_xgb_p5 = roc_auc_score(y_train, xgb_final_p5.predict_proba(X_train_selected_p5)[:, 1])\n",
    "val_auc_xgb_p5 = roc_auc_score(y_val, xgb_final_p5.predict_proba(X_val_selected_p5)[:, 1])\n",
    "\n",
    "print(f\"Final LightGBM - Train AUC: {train_auc_lgb_p5:.4f}, Val AUC: {val_auc_lgb_p5:.4f}\")\n",
    "print(f\"Final XGBoost  - Train AUC: {train_auc_xgb_p5:.4f}, Val AUC: {val_auc_xgb_p5:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb1368d",
   "metadata": {},
   "source": [
    "### Quick Evaluation (80/20 Split - Phase 4 Comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "10572e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "QUICK EVALUATION (80/20 Split)\n",
      "======================================================================\n",
      "   Model  Train AUC  Val AUC  Phase4 Val AUC  Improvement  Train-Val Gap\n",
      "LightGBM   0.862449 0.776472        0.771645     0.004827       0.085977\n",
      " XGBoost   0.929613 0.767688        0.771645    -0.003957       0.161926\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "comparison_p5 = pd.DataFrame({\n",
    "    'Model': ['LightGBM', 'XGBoost'],\n",
    "    'Train AUC': [train_auc_lgb_p5, train_auc_xgb_p5],\n",
    "    'Val AUC': [val_auc_lgb_p5, val_auc_xgb_p5],\n",
    "    'Phase4 Val AUC': [phase4_val_auc_lgb, phase4_val_auc_lgb],\n",
    "    'Improvement': [val_auc_lgb_p5 - phase4_val_auc_lgb, val_auc_xgb_p5 - phase4_val_auc_lgb],\n",
    "    'Train-Val Gap': [train_auc_lgb_p5 - val_auc_lgb_p5, train_auc_xgb_p5 - val_auc_xgb_p5]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"QUICK EVALUATION (80/20 Split)\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_p5.to_string(index=False))\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50acc09",
   "metadata": {},
   "source": [
    "### Cross-Validation (5-Fold StratifiedKFold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "76a7d551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CROSS-VALIDATION (5-Fold)\n",
      "======================================================================\n",
      "LightGBM CV Scores: [0.7799068487370844, 0.7741456018045629, 0.7720889568508112, 0.7746661888004933, 0.7767181455785774]\n",
      "LightGBM Mean: 0.7755 ± 0.0026\n",
      "Phase 4 LightGBM CV: 0.7716\n",
      "Improvement: +0.0039\n",
      "----------------------------------------------------------------------\n",
      "XGBoost CV Scores: [0.772775627346785, 0.7658962098824997, 0.7634166654777013, 0.7655366186151816, 0.7693677006534287]\n",
      "XGBoost Mean: 0.7674 ± 0.0033\n",
      "Phase 4 XGBoost: N/A (using LightGBM baseline)\n",
      "Improvement vs LightGBM: -0.0042\n",
      "======================================================================\n",
      "CPU times: total: 38min 12s\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_full = pd.concat([X_train, X_val], axis=0).reset_index(drop=True)\n",
    "y_full = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    "\n",
    "X_train_p4_full = pd.read_csv('../../data/processed/phase4_pos_cc/X_train.csv')\n",
    "X_val_p4_full = pd.read_csv('../../data/processed/phase4_pos_cc/X_val.csv')\n",
    "X_full_p4 = pd.concat([X_train_p4_full, X_val_p4_full], axis=0).reset_index(drop=True)\n",
    "\n",
    "X_full_p5 = X_full_p4.merge(inst_filtered, on='SK_ID_CURR', how='left').drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "for col in CATEGORICAL_FEATURES:\n",
    "    if col in X_full_p5.columns:\n",
    "        X_full_p5[col] = X_full_p5[col].map(cat_mappings[col]).fillna(-1).astype(int)\n",
    "\n",
    "X_full_selected_p5 = X_full_p5[selected_features_p5]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "lgb_cv_scores_p5 = []\n",
    "xgb_cv_scores_p5 = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_full_selected_p5, y_full), 1):\n",
    "    X_tr, X_va = X_full_selected_p5.iloc[train_idx], X_full_selected_p5.iloc[val_idx]\n",
    "    y_tr, y_va = y_full.iloc[train_idx], y_full.iloc[val_idx]\n",
    "    \n",
    "    lgb_cv = LGBMClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=7,\n",
    "        num_leaves=31,\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    xgb_cv = XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=7,\n",
    "        random_state=42,\n",
    "        scale_pos_weight=(len(y_tr) - y_tr.sum()) / y_tr.sum(),\n",
    "        eval_metric='logloss',\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "    \n",
    "    lgb_cv.fit(X_tr, y_tr, eval_set=[(X_va, y_va)])\n",
    "    xgb_cv.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=False)\n",
    "    \n",
    "    lgb_va_auc = roc_auc_score(y_va, lgb_cv.predict_proba(X_va)[:, 1])\n",
    "    xgb_va_auc = roc_auc_score(y_va, xgb_cv.predict_proba(X_va)[:, 1])\n",
    "    \n",
    "    lgb_cv_scores_p5.append(lgb_va_auc)\n",
    "    xgb_cv_scores_p5.append(xgb_va_auc)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CROSS-VALIDATION (5-Fold)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"LightGBM CV Scores: {lgb_cv_scores_p5}\")\n",
    "print(f\"LightGBM Mean: {np.mean(lgb_cv_scores_p5):.4f} ± {np.std(lgb_cv_scores_p5):.4f}\")\n",
    "print(f\"Phase 4 LightGBM CV: {phase4_val_auc_lgb:.4f}\")\n",
    "print(f\"Improvement: {np.mean(lgb_cv_scores_p5) - phase4_val_auc_lgb:+.4f}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"XGBoost CV Scores: {xgb_cv_scores_p5}\")\n",
    "print(f\"XGBoost Mean: {np.mean(xgb_cv_scores_p5):.4f} ± {np.std(xgb_cv_scores_p5):.4f}\")\n",
    "print(f\"Phase 4 XGBoost: N/A (using LightGBM baseline)\")\n",
    "print(f\"Improvement vs LightGBM: {np.mean(xgb_cv_scores_p5) - phase4_val_auc_lgb:+.4f}\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb5f592",
   "metadata": {},
   "source": [
    "### Save Processed Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "8b8636d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ../../data/processed/phase5_installments/\n"
     ]
    }
   ],
   "source": [
    "output_dir_p5 = '../../data/processed/phase5_installments'\n",
    "os.makedirs(output_dir_p5, exist_ok=True)\n",
    "\n",
    "train_df_p5[['SK_ID_CURR'] + selected_features_p5].to_csv(f'{output_dir_p5}/X_train.csv', index=False)\n",
    "pd.DataFrame(y_train).to_csv(f'{output_dir_p5}/y_train.csv', index=False)\n",
    "\n",
    "val_df_p5[['SK_ID_CURR'] + selected_features_p5].to_csv(f'{output_dir_p5}/X_val.csv', index=False)\n",
    "pd.DataFrame(y_val).to_csv(f'{output_dir_p5}/y_val.csv', index=False)\n",
    "\n",
    "test_df_p5[['SK_ID_CURR'] + selected_features_p5].to_csv(f'{output_dir_p5}/X_test.csv', index=False)\n",
    "\n",
    "feature_metadata_p5 = {\n",
    "    'phase': 5,\n",
    "    'base_phase': 4,\n",
    "    'base_features': len(phase4_selected_features),\n",
    "    'inst_features_created': len(inst_cols),\n",
    "    'inst_features_after_l1': len(inst_filtered.columns) - 1,\n",
    "    'features_dropped_missing': inst_missing_dropped,\n",
    "    'features_dropped_variance': inst_var_dropped,\n",
    "    'features_dropped_correlation': inst_corr_dropped,\n",
    "    'importance_threshold': importance_threshold,\n",
    "    'features_selected_lgb': len(lgb_selected_p5),\n",
    "    'features_selected_xgb': len(xgb_selected_p5),\n",
    "    'feature_list': selected_features_p5,\n",
    "    'quick_eval': {\n",
    "        'lgb_train_auc': train_auc_lgb_p5,\n",
    "        'lgb_val_auc': val_auc_lgb_p5,\n",
    "        'xgb_train_auc': train_auc_xgb_p5,\n",
    "        'xgb_val_auc': val_auc_xgb_p5,\n",
    "        'phase4_baseline': phase4_val_auc_lgb\n",
    "    },\n",
    "    'cv_eval': {\n",
    "        'lgb_cv_scores': lgb_cv_scores_p5,\n",
    "        'lgb_cv_mean': np.mean(lgb_cv_scores_p5),\n",
    "        'lgb_cv_std': np.std(lgb_cv_scores_p5),\n",
    "        'xgb_cv_scores': xgb_cv_scores_p5,\n",
    "        'xgb_cv_mean': np.mean(xgb_cv_scores_p5),\n",
    "        'xgb_cv_std': np.std(xgb_cv_scores_p5)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f'{output_dir_p5}/feature_metadata.json', 'w') as f:\n",
    "    json.dump(feature_metadata_p5, f, indent=2)\n",
    "\n",
    "print(f\"Processed data saved to {output_dir_p5}/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f38f6a1",
   "metadata": {},
   "source": [
    "### MLflow Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "d76bb4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/13 00:54:45 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/13 00:54:50 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c4fe267526486bb88f5fe6bc07bccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/13 00:54:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged LightGBM to MLflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/13 00:54:55 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8adbe342f64ddea179a7564fa9f310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged XGBoost to MLflow\n"
     ]
    }
   ],
   "source": [
    "mlflow_tracking_uri = os.path.join(os.getcwd(), 'mlruns')\n",
    "mlflow.set_tracking_uri(f\"file:///{mlflow_tracking_uri}\")\n",
    "\n",
    "mlflow.set_experiment(\"feature_engineering\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"phase5_installments_lightgbm\"):\n",
    "    mlflow.log_param(\"phase\", \"installments\")\n",
    "    mlflow.log_param(\"base_phase\", \"phase4_pos_cc\")\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM\")\n",
    "    mlflow.log_param(\"n_estimators\", 500)\n",
    "    mlflow.log_param(\"learning_rate\", 0.05)\n",
    "    mlflow.log_param(\"max_depth\", 7)\n",
    "    mlflow.log_param(\"num_leaves\", 31)\n",
    "    mlflow.log_param(\"n_phase4_features\", len(phase4_selected_features))\n",
    "    mlflow.log_param(\"n_inst_features_created\", len(inst_cols))\n",
    "    mlflow.log_param(\"n_inst_features_after_l1\", len(inst_filtered.columns) - 1)\n",
    "    mlflow.log_param(\"n_features_final\", len(selected_features_p5))\n",
    "    mlflow.log_param(\"importance_threshold\", importance_threshold)\n",
    "    \n",
    "    mlflow.log_metric(\"quick_train_auc\", train_auc_lgb_p5)\n",
    "    mlflow.log_metric(\"quick_val_auc\", val_auc_lgb_p5)\n",
    "    mlflow.log_metric(\"cv_mean_auc\", np.mean(lgb_cv_scores_p5))\n",
    "    mlflow.log_metric(\"cv_std_auc\", np.std(lgb_cv_scores_p5))\n",
    "    mlflow.log_metric(\"phase4_val_auc\", phase4_val_auc_lgb)\n",
    "    mlflow.log_metric(\"improvement_quick\", val_auc_lgb_p5 - phase4_val_auc_lgb)\n",
    "    mlflow.log_metric(\"improvement_cv\", np.mean(lgb_cv_scores_p5) - phase4_val_auc_lgb)\n",
    "    \n",
    "    X_sample = X_train_selected_p5.iloc[:5].fillna(0)\n",
    "    y_sample = y_train.iloc[:5]\n",
    "    signature = infer_signature(X_sample, y_sample)\n",
    "    \n",
    "    mlflow.sklearn.log_model(lgb_final_p5, \"model\", signature=signature, input_example=X_sample)\n",
    "    \n",
    "    lgb_imp_df = get_feature_importances(lgb_final_p5, selected_features_p5)\n",
    "    lgb_imp_df.to_csv('feature_importance_lgb_p5.csv', index=False)\n",
    "    mlflow.log_artifact('feature_importance_lgb_p5.csv')\n",
    "    os.remove('feature_importance_lgb_p5.csv')\n",
    "    \n",
    "    with open('selected_features_p5.json', 'w') as f:\n",
    "        json.dump({'features': selected_features_p5}, f, indent=2)\n",
    "    mlflow.log_artifact('selected_features_p5.json')\n",
    "    os.remove('selected_features_p5.json')\n",
    "    \n",
    "    with open('dropped_features_p5.json', 'w') as f:\n",
    "        json.dump({\n",
    "            'dropped_missing': inst_missing_dropped,\n",
    "            'dropped_variance': inst_var_dropped,\n",
    "            'dropped_correlation': inst_corr_dropped\n",
    "        }, f, indent=2)\n",
    "    mlflow.log_artifact('dropped_features_p5.json')\n",
    "    os.remove('dropped_features_p5.json')\n",
    "\n",
    "print(\"Logged LightGBM to MLflow\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"phase5_installments_xgboost\"):\n",
    "    mlflow.log_param(\"phase\", \"installments\")\n",
    "    mlflow.log_param(\"base_phase\", \"phase4_pos_cc\")\n",
    "    mlflow.log_param(\"model_type\", \"XGBoost\")\n",
    "    mlflow.log_param(\"n_estimators\", 500)\n",
    "    mlflow.log_param(\"learning_rate\", 0.05)\n",
    "    mlflow.log_param(\"max_depth\", 7)\n",
    "    mlflow.log_param(\"n_phase4_features\", len(phase4_selected_features))\n",
    "    mlflow.log_param(\"n_inst_features_created\", len(inst_cols))\n",
    "    mlflow.log_param(\"n_inst_features_after_l1\", len(inst_filtered.columns) - 1)\n",
    "    mlflow.log_param(\"n_features_final\", len(selected_features_p5))\n",
    "    mlflow.log_param(\"importance_threshold\", importance_threshold)\n",
    "    \n",
    "    mlflow.log_metric(\"quick_train_auc\", train_auc_xgb_p5)\n",
    "    mlflow.log_metric(\"quick_val_auc\", val_auc_xgb_p5)\n",
    "    mlflow.log_metric(\"cv_mean_auc\", np.mean(xgb_cv_scores_p5))\n",
    "    mlflow.log_metric(\"cv_std_auc\", np.std(xgb_cv_scores_p5))\n",
    "    mlflow.log_metric(\"phase4_val_auc\", phase4_val_auc_lgb)\n",
    "    mlflow.log_metric(\"improvement_quick\", val_auc_xgb_p5 - phase4_val_auc_lgb)\n",
    "    mlflow.log_metric(\"improvement_cv\", np.mean(xgb_cv_scores_p5) - phase4_val_auc_lgb)\n",
    "    \n",
    "    X_sample = X_train_selected_p5.iloc[:5].fillna(0)\n",
    "    y_sample = y_train.iloc[:5]\n",
    "    signature = infer_signature(X_sample, y_sample)\n",
    "    \n",
    "    mlflow.sklearn.log_model(xgb_final_p5, \"model\", signature=signature, input_example=X_sample)\n",
    "    \n",
    "    xgb_imp_df = get_feature_importances(xgb_final_p5, selected_features_p5)\n",
    "    xgb_imp_df.to_csv('feature_importance_xgb_p5.csv', index=False)\n",
    "    mlflow.log_artifact('feature_importance_xgb_p5.csv')\n",
    "    os.remove('feature_importance_xgb_p5.csv')\n",
    "    \n",
    "    with open('selected_features_p5.json', 'w') as f:\n",
    "        json.dump({'features': selected_features_p5}, f, indent=2)\n",
    "    mlflow.log_artifact('selected_features_p5.json')\n",
    "    os.remove('selected_features_p5.json')\n",
    "    \n",
    "    with open('dropped_features_p5.json', 'w') as f:\n",
    "        json.dump({\n",
    "            'dropped_missing': inst_missing_dropped,\n",
    "            'dropped_variance': inst_var_dropped,\n",
    "            'dropped_correlation': inst_corr_dropped\n",
    "        }, f, indent=2)\n",
    "    mlflow.log_artifact('dropped_features_p5.json')\n",
    "    os.remove('dropped_features_p5.json')\n",
    "\n",
    "print(\"Logged XGBoost to MLflow\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4470621",
   "metadata": {},
   "source": [
    "### Save Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "688c27e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../../models/phase5_installments/lightgbm_v1.pkl\n",
      "Model saved to ../../models/phase5_installments/xgboost_v1.pkl\n"
     ]
    }
   ],
   "source": [
    "output_model_dir_p5 = '../../models/phase5_installments'\n",
    "os.makedirs(output_model_dir_p5, exist_ok=True)\n",
    "\n",
    "model_artifacts_lgb_p5 = {\n",
    "    'model': lgb_final_p5,\n",
    "    'selected_features': selected_features_p5,\n",
    "    'categorical_features': CATEGORICAL_FEATURES,\n",
    "    'cat_mappings': cat_mappings,\n",
    "    'quick_val_auc': val_auc_lgb_p5,\n",
    "    'cv_mean_auc': np.mean(lgb_cv_scores_p5),\n",
    "    'cv_std_auc': np.std(lgb_cv_scores_p5),\n",
    "    'phase4_val_auc': phase4_val_auc_lgb,\n",
    "    'improvement': val_auc_lgb_p5 - phase4_val_auc_lgb\n",
    "}\n",
    "\n",
    "joblib.dump(model_artifacts_lgb_p5, f'{output_model_dir_p5}/lightgbm_v1.pkl')\n",
    "print(f\"Model saved to {output_model_dir_p5}/lightgbm_v1.pkl\")\n",
    "\n",
    "model_artifacts_xgb_p5 = {\n",
    "    'model': xgb_final_p5,\n",
    "    'selected_features': selected_features_p5,\n",
    "    'categorical_features': CATEGORICAL_FEATURES,\n",
    "    'cat_mappings': cat_mappings,\n",
    "    'quick_val_auc': val_auc_xgb_p5,\n",
    "    'cv_mean_auc': np.mean(xgb_cv_scores_p5),\n",
    "    'cv_std_auc': np.std(xgb_cv_scores_p5),\n",
    "    'phase4_val_auc': phase4_val_auc_lgb,\n",
    "    'improvement': val_auc_xgb_p5 - phase4_val_auc_lgb\n",
    "}\n",
    "\n",
    "joblib.dump(model_artifacts_xgb_p5, f'{output_model_dir_p5}/xgboost_v1.pkl')\n",
    "print(f\"Model saved to {output_model_dir_p5}/xgboost_v1.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b54dd56",
   "metadata": {},
   "source": [
    "### Generate Kaggle Submissions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "eee6c82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission files created:\n",
      "  phase5_installments_lightgbm_v1.csv\n",
      "  phase5_installments_xgboost_v1.csv\n",
      "\n",
      "LightGBM predictions - Min: 0.0038, Max: 0.9576, Mean: 0.3527\n",
      "XGBoost predictions  - Min: 0.0020, Max: 0.9587, Mean: 0.3063\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('../../data/raw/sample_submission.csv')\n",
    "\n",
    "lgb_preds_p5 = lgb_final_p5.predict_proba(X_test_selected_p5)[:, 1]\n",
    "xgb_preds_p5 = xgb_final_p5.predict_proba(X_test_selected_p5)[:, 1]\n",
    "\n",
    "submission_lgb_p5 = sample_submission.copy()\n",
    "submission_lgb_p5['TARGET'] = lgb_preds_p5\n",
    "\n",
    "submission_xgb_p5 = sample_submission.copy()\n",
    "submission_xgb_p5['TARGET'] = xgb_preds_p5\n",
    "\n",
    "os.makedirs('../../data/submissions', exist_ok=True)\n",
    "\n",
    "submission_lgb_p5.to_csv('../../data/submissions/phase5_installments_lightgbm_v1.csv', index=False)\n",
    "submission_xgb_p5.to_csv('../../data/submissions/phase5_installments_xgboost_v1.csv', index=False)\n",
    "\n",
    "print(\"Submission files created:\")\n",
    "print(\"  phase5_installments_lightgbm_v1.csv\")\n",
    "print(\"  phase5_installments_xgboost_v1.csv\")\n",
    "print(f\"\\nLightGBM predictions - Min: {lgb_preds_p5.min():.4f}, Max: {lgb_preds_p5.max():.4f}, Mean: {lgb_preds_p5.mean():.4f}\")\n",
    "print(f\"XGBoost predictions  - Min: {xgb_preds_p5.min():.4f}, Max: {xgb_preds_p5.max():.4f}, Mean: {xgb_preds_p5.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474d1c2b",
   "metadata": {},
   "source": [
    "### Phase 5 Summary\n",
    "\n",
    "**Strategy:** Installments payment discipline - timing delays and payment patterns - second highest impact phase.\n",
    "\n",
    "**Features Created:** 30 installments features (AMT_INSTALMENT, AMT_PAYMENT, DAYS_INSTALMENT, DAYS_ENTRY_PAYMENT, payment_delay, payment_diff, payment_ratio, late_payment_count/ratio). Level 1 filtering: 11 correlation drops → 19 features. Level 2 selection (LightGBM only): All 19 retained. Final: 95 features total.\n",
    "\n",
    "**Results:** LightGBM Val 0.7765, CV 0.7755 (+0.0039 from Phase 4). XGBoost Val 0.7677, CV 0.7674. Kaggle: LightGBM Private 0.76940/Public 0.76412 (BEST), XGBoost Private 0.76028/Public 0.75618.\n",
    "\n",
    "**Top Contributors:** inst_late_payment_count, inst_payment_delay aggregations, inst_payment_diff patterns, inst_payment_ratio metrics. Payment discipline strong signal.\n",
    "\n",
    "**Insight:** Strong phase. Payment timing and delays highly predictive. Final model: 95 features, +0.0212 CV AUC improvement over baseline.\n",
    "\n",
    "**Saved:** Processed data and models to phase5_installments/, tracked in MLflow, submissions generated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
